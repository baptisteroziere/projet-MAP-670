{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import scipy\n",
    "import csv\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.csr_matrix(( loader['data'], loader['indices'], loader['indptr']),\n",
    "                     shape = loader['shape'])\n",
    "        \n",
    "def load_csv(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = '\\n')\n",
    "        array = [float(row[0]) for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_feature_names(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter= '\\n')\n",
    "        array = [row for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_sparse_coo(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.coo_matrix((loader['data'],(loader['row'],loader['col'])),\n",
    "                     shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750, 200000)\n"
     ]
    }
   ],
   "source": [
    "path = \"bapt_tfidf/\"\n",
    "data_train = load_sparse_csr(path+'data_train.npz')\n",
    "data_test = load_sparse_csr(path+'data_test.npz')\n",
    "label_train = load_csv(path+'label_train.csv')\n",
    "label_test = load_csv(path+'label_test.csv')\n",
    "features_names = load_feature_names('data/feature_names.csv')\n",
    "print data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "def score(true_label, predicted_label):\n",
    "    return 1 - zero_one_loss(true_label,predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_all = [load_sparse_csr('tw_sw{}_all_train_train.npz'.format(k)) for k in range(1,6)]\n",
    "data_test_all = [load_sparse_csr('tw_sw{}_all_train_test.npz'.format(k)) for k in range(1,6)]\n",
    "data_train_sep = [load_sparse_coo('tw_sw{}_train_train.npz'.format(k)) for k in range(1,6)]\n",
    "data_test_sep = [load_sparse_coo('tw_sw{}_train_test.npz'.format(k)) for k in range(1,6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_train_tw = load_csv('labels_train_train.csv')\n",
    "label_test_tw = load_csv('labels_train_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750, 80000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:165: RuntimeWarning: invalid value encountered in divide\n",
      "  chisq /= f_exp\n"
     ]
    }
   ],
   "source": [
    "nb_feat = 80000\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "fselect = SelectKBest(chi2 , k=nb_feat)\n",
    "data_train = fselect.fit_transform(data_train, label_train)\n",
    "data_test = fselect.transform(data_test)\n",
    "print data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "normalizer_all = map(lambda x: MaxAbsScaler().fit(x), data_train_all)\n",
    "normalizer_sep = map(lambda x: MaxAbsScaler().fit(x), data_train_sep)\n",
    "\n",
    "scaler =MaxAbsScaler()\n",
    "scaler.partial_fit(data_test)\n",
    "scaler.partial_fit(data_train)\n",
    "scaler.transform(data_test)\n",
    "scaler.transform(data_train)\n",
    "\n",
    "data_train_all_norm = [normalizer_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_norm = [normalizer_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n",
    "data_train_sep_norm = [normalizer_sep[i].transform(data_train_sep[i]) for i in range(len(data_train_sep))]\n",
    "data_test_sep_norm = [normalizer_sep[i].transform(data_test_sep[i]) for i in range(len(data_test_sep))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 0 0 ..., 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 0 0 0 0 0 0 0 0 0] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "SelectKBest(f_classif , k=data_train_all[0].shape[1]/100).fit(data_train_all[0],label_train_tw)\n",
    "fselect_all = [SelectKBest(f_classif , k=data_train_all[i].shape[1]/100).fit(\n",
    "        data_train_all[i],label_train_tw) for i in range(len(data_train_all))]\n",
    "fselect_sep = [SelectKBest(f_classif , k=data_train_sep[i].shape[1]/100).fit(\n",
    "        data_train_sep[i], label_train_tw) for i in range(len(data_train_sep))]\n",
    "data_train_all_selec = [fselect_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_selec = [fselect_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n",
    "\n",
    "data_train_sep_selec = [fselect_sep[i].transform(data_train_sep[i]) for i in range(len(data_train_sep))]\n",
    "data_test_sep_selec = [fselect_sep[i].transform(data_test_sep[i]) for i in range(len(data_test_sep))]\n",
    "fselect_all_norm = [SelectKBest(f_classif , k=data_train_all_norm[i].shape[1]/100).fit(\n",
    "        data_train_all_norm[i],label_train_tw) for i in range(len(data_train_all_norm))]\n",
    "fselect_sep_norm = [SelectKBest(f_classif , k=data_train_sep[i].shape[1]/100).fit(\n",
    "        data_train_sep_norm[i], label_train_tw) for i in range(len(data_train_sep_norm))]\n",
    "\n",
    "data_train_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_train_all_norm[i]) for i in range(len(data_train_all_norm))]\n",
    "data_test_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_test_all_norm[i]) for i in range(len(data_test_all_norm))]\n",
    "data_train_sep_norm_selec = [fselect_sep_norm[i].transform(\n",
    "        data_train_sep_norm[i]) for i in range(len(data_train_sep_norm))]\n",
    "data_test_sep_norm_selec = [fselect_sep_norm[i].transform(\n",
    "        data_test_sep_norm[i]) for i in range(len(data_test_sep_norm))]\n",
    "\n",
    "data_train_tw = data_train_all_norm [3]\n",
    "data_test_tw = data_test_all_norm [3]\n",
    "\n",
    "data_train_tw = data_train_tw[:,0:-25]\n",
    "data_test_tw = data_train_tw[:,0:-25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-0361cd1953ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[0mdata_train_all_norm_selec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print data_train_all_norm_selec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "- Adding the proba (instead of the label) is better for the final predition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVM - Best C & associated score', {'C': 1388.8888888888889}, 0.92437333333333338)\n",
      "('SVM - Score on test_data : ', 0.90544000000000002)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(1000, 1500, 10)}\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrtf = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "lrtf = lrtf.fit(data_train, label_train)\n",
    "predicted_label_lrtf = lrtf.predict(data_test)\n",
    "\n",
    "\n",
    "print(\"SVM - Best C & associated score\", lrtf.best_params_, lrtf.best_score_)\n",
    "print(\"SVM - Score on test_data : \", score(label_test, predicted_label_lrtf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVM - Best C & associated score', {'C': 0.62105263157894741}, 0.87680000000000002)\n",
      "('SVM - Score on test_data : ', 0.88127999999999995)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(0.4, 1, 20)}\n",
    "\n",
    "lrtw = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "lrtw = lrtw.fit(data_train_tw, label_train_tw)\n",
    "predicted_label_lrtw = lrtw.predict(data_test_tw)\n",
    "\n",
    "print(\"SVM - Best C & associated score\", lrtw.best_params_, lrtw.best_score_)\n",
    "print(\"SVM - Score on test_data : \", score(label_test, predicted_label_lrtw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier\n",
    "- Impossible to predict a proba, just labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD - Score on test data : ', 0.90383999999999998)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_tf = SGDClassifier(loss='modified_huber', n_iter=100, random_state=0, shuffle=True, penalty='l2')\n",
    "sgd_tf.fit( data_train, label_train )\n",
    "predicted_label_SGD_TF = sgd_tf.predict(data_test)\n",
    "\n",
    "print(\"SGD - Score on test data : \", score(label_test, predicted_label_SGD_TF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD - Score on test data : ', 0.86736000000000002)\n"
     ]
    }
   ],
   "source": [
    "sgd_tw = SGDClassifier(loss='modified_huber', n_iter=100, random_state=0, shuffle=True, penalty='l2')\n",
    "sgd_tw.fit( data_train_tw, label_train )\n",
    "predicted_label_SGD_TW = sgd_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"SGD - Score on test data : \", score(label_test, predicted_label_SGD_TW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC\n",
    "- Do not predict proba, only labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear SVC - Best C & associated score', {'C': 4.333333333333333}, 0.92458666666666667)\n",
      "('Linear svc  - Score on test_data : ', 0.90527999999999997)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Cs = {'C': np.linspace(3, 5, 10)}\n",
    "svc_tf = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "svc_tf.fit(data_train, label_train)\n",
    "predicted_label_SVC_TF = svc_tf.predict(data_test)\n",
    "\n",
    "print(\"Linear SVC - Best C & associated score\", svc_tf.best_params_, svc_tf.best_score_)\n",
    "print(\"Linear svc  - Score on test_data : \", score(predicted_label_SVC_TF, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear SVC - Best C & associated score', {'C': 0.032500000000000001}, 0.87690666666666661)\n",
      "('linear svc  - Score on test_data : ', 0.88160000000000005)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(0.01, 0.1, 5)}\n",
    "svc_tw = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "svc_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_SVC_TW = svc_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"Linear SVC - Best C & associated score\", svc_tw.best_params_, svc_tw.best_score_)\n",
    "print(\"linear svc  - Score on test_data : \", score(predicted_label_SVC_TW, label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n",
    "- Able to return the label, the proba, and the log_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Multinomial - Best alpha & associated score', {'alpha': 0.00029999999999999997}, 0.95413333333333339)\n",
      "('MNB  - Score on test_data : ', 0.88736000000000004)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "alphas = {'alpha': np.linspace(0.0001, 0.001, 10)}\n",
    "multinom_tf = GridSearchCV(MultinomialNB(), alphas, n_jobs = 1)\n",
    "multinom_tf.fit(data_train, label_train)\n",
    "predicted_label_MN_TF = multinom_tf.predict(data_test)\n",
    "\n",
    "print(\"Multinomial - Best alpha & associated score\", multinom_tf.best_params_, multinom_tf.best_score_)\n",
    "print(\"MNB  - Score on test_data : \", score(predicted_label_MN_TF, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nalphas = {\\'alpha\\': np.logspace(-3, 0, 10)}\\nmultinom_tw = GridSearchCV(MultinomialNB(), alphas, n_jobs = 1)\\nmultinom_tw.fit(data_train_tw, label_train)\\npredicted_label_MN_TW = multinom_tw.predict(data_test_tw)\\n\\nprint(\"Multinomial - Best alpha & associated score\", multinom_tw.best_params_, multinom_tw.best_score_)\\nprint(\"MNB  - Score on test_data : \", score(predicted_label_MN_TW, label_test))\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DO NOT WORK BECAUSE THE VALUES NEED TO BE POSITIVE APPARENTLY\n",
    "'''\n",
    "alphas = {'alpha': np.logspace(-3, 0, 10)}\n",
    "multinom_tw = GridSearchCV(MultinomialNB(), alphas, n_jobs = 1)\n",
    "multinom_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_MN_TW = multinom_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"Multinomial - Best alpha & associated score\", multinom_tw.best_params_, multinom_tw.best_score_)\n",
    "print(\"MNB  - Score on test_data : \", score(predicted_label_MN_TW, label_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTrees\n",
    "- Can predict label, proba AND log proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTrees - Score on test_data : ', 0.84192)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extratrees_tf = ExtraTreesClassifier(n_estimators=40, max_depth=None, min_samples_split=1, random_state=0, n_jobs = 1)\n",
    "extratrees_tf.fit(data_train, label_train)\n",
    "predicted_label_extratrees_tf = extratrees_tf.predict(data_test)\n",
    "\n",
    "print(\"ExtraTrees - Score on test_data : \", score(label_test, predicted_label_extratrees_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTrees - Score on test_data : ', 0.82320000000000004)\n"
     ]
    }
   ],
   "source": [
    "extratrees_tw = ExtraTreesClassifier(n_estimators=40, max_depth=None, min_samples_split=1, random_state=0, n_jobs = 1)\n",
    "extratrees_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_extratrees_tw = extratrees_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"ExtraTrees - Score on test_data : \", score(label_test, predicted_label_extratrees_tw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "- Can predict label, proba AND log proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AdaBoost - Score on test_data : ', 0.78895999999999999)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_tf = AdaBoostClassifier(n_estimators=40)\n",
    "adaboost_tf.fit(data_train, label_train)\n",
    "predicted_label_adaboost_tf = adaboost_tf.predict(data_test)\n",
    "\n",
    "print(\"AdaBoost - Score on test_data : \", score(label_test, predicted_label_adaboost_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AdaBoost - Score on test_data : ', 0.79520000000000002)\n"
     ]
    }
   ],
   "source": [
    "adaboost_tw = AdaBoostClassifier(n_estimators=40)\n",
    "adaboost_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_adaboost_tw = adaboost_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"AdaBoost - Score on test_data : \", score(label_test, predicted_label_adaboost_tw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the difference in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_similarity(l1, l2):#\n",
    "    ref_diff =0\n",
    "    all_diff =0\n",
    "\n",
    "    for i, label in enumerate(l1):\n",
    "        if(label != label_test[i]):\n",
    "            ref_diff+=1\n",
    "            if(label_test[i] != l2[i]):\n",
    "                all_diff+=1\n",
    "    return ref_diff, all_diff, float(all_diff)/ref_diff *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 75, 12.690355329949238) lrtf sgd_tw\n",
      "(591, 69, 11.6751269035533) lrtf lrtw\n",
      "(591, 72, 12.18274111675127) lrtf svc_tw\n",
      "(591, 125, 21.150592216582066) lrtf adaboost_tw\n",
      "(591, 119, 20.135363790186126) lrtf extratrees_tw\n",
      "(592, 71, 11.993243243243242) svc_tf sgd_tw\n",
      "(592, 65, 10.97972972972973) svc_tf lrtw\n",
      "(592, 68, 11.486486486486488) svc_tf svc_tw\n",
      "(592, 126, 21.283783783783782) svc_tf adaboost_tw\n",
      "(592, 117, 19.763513513513516) svc_tf extratrees_tw\n",
      "(988, 120, 12.145748987854251) extratrees_tf sgd_tw\n",
      "(988, 108, 10.931174089068826) extratrees_tf lrtw\n",
      "(988, 108, 10.931174089068826) extratrees_tf svc_tw\n",
      "(988, 197, 19.939271255060728) extratrees_tf adaboost_tw\n",
      "(988, 177, 17.91497975708502) extratrees_tf extratrees_tw\n",
      "(1319, 163, 12.357846853677028) adaboost_tf sgd_tw\n",
      "(1319, 144, 10.917361637604246) adaboost_tf lrtw\n",
      "(1319, 144, 10.917361637604246) adaboost_tf svc_tw\n",
      "(1319, 254, 19.257012888551934) adaboost_tf adaboost_tw\n",
      "(1319, 209, 15.845337376800606) adaboost_tf extratrees_tw\n",
      "(704, 91, 12.926136363636365) multinomial_tf sgd_tw\n",
      "(704, 82, 11.647727272727272) multinomial_tf lrtw\n",
      "(704, 84, 11.931818181818182) multinomial_tf svc_tw\n",
      "(704, 149, 21.164772727272727) multinomial_tf adaboost_tw\n",
      "(704, 132, 18.75) multinomial_tf extratrees_tw\n",
      "(601, 71, 11.813643926788686) sgd_tf sgd_tw\n",
      "(601, 65, 10.8153078202995) sgd_tf lrtw\n",
      "(601, 66, 10.98169717138103) sgd_tf svc_tw\n",
      "(601, 124, 20.632279534109816) sgd_tf adaboost_tw\n",
      "(601, 113, 18.80199667221298) sgd_tf extratrees_tw\n",
      "------------------------------------------\n",
      "(591, 575, 97.29272419627749) lrtf svc_tf\n",
      "(591, 395, 66.83587140439933) lrtf extratrees_tf\n",
      "(591, 355, 60.06768189509306) lrtf adaboost_tf\n",
      "(591, 350, 59.22165820642979) lrtf multinomial_tf\n",
      "(591, 504, 85.27918781725889) lrtf sgd_tf\n",
      "(592, 575, 97.12837837837837) svc_tf lrtf\n",
      "(592, 388, 65.54054054054053) svc_tf extratrees_tf\n",
      "(592, 353, 59.62837837837838) svc_tf adaboost_tf\n",
      "(592, 346, 58.445945945945944) svc_tf multinomial_tf\n",
      "(592, 499, 84.29054054054053) svc_tf sgd_tf\n",
      "(988, 395, 39.979757085020246) extratrees_tf lrtf\n",
      "(988, 388, 39.27125506072874) extratrees_tf svc_tf\n",
      "(988, 565, 57.18623481781376) extratrees_tf adaboost_tf\n",
      "(988, 404, 40.89068825910931) extratrees_tf multinomial_tf\n",
      "(988, 445, 45.040485829959515) extratrees_tf sgd_tf\n",
      "(1319, 355, 26.914329037149354) adaboost_tf lrtf\n",
      "(1319, 353, 26.762699014404852) adaboost_tf svc_tf\n",
      "(1319, 565, 42.835481425322214) adaboost_tf extratrees_tf\n",
      "(1319, 374, 28.354814253222138) adaboost_tf multinomial_tf\n",
      "(1319, 392, 29.71948445792267) adaboost_tf sgd_tf\n",
      "(704, 350, 49.715909090909086) multinomial_tf lrtf\n",
      "(704, 346, 49.14772727272727) multinomial_tf svc_tf\n",
      "(704, 404, 57.38636363636363) multinomial_tf extratrees_tf\n",
      "(704, 374, 53.125) multinomial_tf adaboost_tf\n",
      "(704, 381, 54.11931818181818) multinomial_tf sgd_tf\n",
      "(601, 504, 83.86023294509151) sgd_tf lrtf\n",
      "(601, 499, 83.02828618968387) sgd_tf svc_tf\n",
      "(601, 445, 74.04326123128119) sgd_tf extratrees_tf\n",
      "(601, 392, 65.22462562396007) sgd_tf adaboost_tf\n",
      "(601, 381, 63.394342762063225) sgd_tf multinomial_tf\n",
      "------------------------------------------\n",
      "(829, 635, 76.59831121833534) sgd_tw lrtw\n",
      "(829, 627, 75.63329312424608) sgd_tw svc_tw\n",
      "(829, 441, 53.196622436670694) sgd_tw adaboost_tw\n",
      "(829, 467, 56.332931242460795) sgd_tw extratrees_tw\n",
      "(742, 635, 85.57951482479784) lrtw sgd_tw\n",
      "(742, 712, 95.95687331536388) lrtw svc_tw\n",
      "(742, 430, 57.95148247978437) lrtw adaboost_tw\n",
      "(742, 479, 64.55525606469003) lrtw extratrees_tw\n",
      "(740, 627, 84.72972972972973) svc_tw sgd_tw\n",
      "(740, 712, 96.21621621621622) svc_tw lrtw\n",
      "(740, 434, 58.648648648648646) svc_tw adaboost_tw\n",
      "(740, 482, 65.13513513513513) svc_tw extratrees_tw\n",
      "(1280, 441, 34.453125) adaboost_tw sgd_tw\n",
      "(1280, 430, 33.59375) adaboost_tw lrtw\n",
      "(1280, 434, 33.90625) adaboost_tw svc_tw\n",
      "(1280, 513, 40.078125) adaboost_tw extratrees_tw\n",
      "(1105, 467, 42.262443438914026) extratrees_tw sgd_tw\n",
      "(1105, 479, 43.34841628959276) extratrees_tw lrtw\n",
      "(1105, 482, 43.619909502262445) extratrees_tw svc_tw\n",
      "(1105, 513, 46.425339366515836) extratrees_tw adaboost_tw\n"
     ]
    }
   ],
   "source": [
    "predicted_label_TF = {\"lrtf\": predicted_label_lrtf, \n",
    "                      \"sgd_tf\" : predicted_label_SGD_TF, \n",
    "                      \"svc_tf\" :predicted_label_SVC_TF,\n",
    "                      \"multinomial_tf\" : predicted_label_MN_TF,\n",
    "                      \"extratrees_tf\" : predicted_label_extratrees_tf,\n",
    "                      \"adaboost_tf\" : predicted_label_adaboost_tf,\n",
    "                      }\n",
    "                      \n",
    "predicted_label_TW = {\"lrtw\": predicted_label_lrtw, \n",
    "                      \"sgd_tw\" : predicted_label_SGD_TW, \n",
    "                      \"svc_tw\" :predicted_label_SVC_TW,\n",
    "                      \"extratrees_tw\" : predicted_label_extratrees_tw,\n",
    "                      \"adaboost_tw\" : predicted_label_adaboost_tw,\n",
    "                      }\n",
    "\n",
    "for tfkey, tfvalue in predicted_label_TF.items():\n",
    "    for twkey, twvalue in predicted_label_TW.items():\n",
    "        print error_similarity(tfvalue,twvalue), tfkey, twkey\n",
    "\n",
    "print '------------------------------------------'\n",
    "\n",
    "for tfkey, tfvalue in predicted_label_TF.items():\n",
    "    for tfkey2, tfvalue2 in predicted_label_TF.items():\n",
    "        if tfkey != tfkey2:\n",
    "            print error_similarity(tfvalue,tfvalue2), tfkey, tfkey2\n",
    "            \n",
    "print '------------------------------------------'\n",
    "\n",
    "for twkey, twvalue in predicted_label_TW.items():\n",
    "    for twkey2, twvalue2 in predicted_label_TW.items():\n",
    "        if twkey != twkey2:\n",
    "            print error_similarity(twvalue,twvalue2), twkey, twkey2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def csr_vappend(a,b): #b est un vecteur ligne (np.array ou liste) et a est une sparse matrix\n",
    "    if(type(a)== list):\n",
    "        a=np.array([a]).T\n",
    "    if(type(b)== list):\n",
    "        b=np.array([b]).T\n",
    "    if(type(a)!= scipy.sparse.csr.csr_matrix):\n",
    "        a=scipy.sparse.csr_matrix(a)\n",
    "    if(type(b)!= scipy.sparse.csr.csr_matrix):\n",
    "        b=scipy.sparse.csr_matrix(b)\n",
    "        \n",
    "    return scipy.sparse.hstack([a,b], format ='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "created_features_train = load_sparse_csr(path+'train_new_feat.npz')\n",
    "created_features_test  = load_sparse_csr(path+'test_new_feat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### LOG REG ######\n",
    "\n",
    "# Add PROBA Logistic Regression TF\n",
    "new_feat_train = lrtf.predict_proba(data_train)[:,0].tolist()\n",
    "new_feat_test = lrtf.predict_proba(data_test)[:,0].tolist()\n",
    "\n",
    "# Add PROBA Logistic Regression TW\n",
    "new_feat_train = csr_vappend(new_feat_train, lrtw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, lrtw.predict_proba(data_test_tw)[:,0].tolist())\n",
    "\n",
    "###### SGD ########\n",
    "\n",
    "# Add SGD TF\n",
    "new_feat_train = csr_vappend(new_feat_train, sgd_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, sgd_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add SGD TW\n",
    "new_feat_train = csr_vappend(new_feat_train, sgd_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, sgd_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### LINEAR SVC #######\n",
    "\n",
    "# Add Linear SVC TF\n",
    "new_feat_train = csr_vappend(new_feat_train, svc_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, svc_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add Linear SVC TW\n",
    "new_feat_train = csr_vappend(new_feat_train, svc_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, svc_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### MULTINOMIAL NAIVE BAYES ######\n",
    "\n",
    "# Add Multinomial TF\n",
    "new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA Multinomial TF\n",
    "new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict_proba(data_train)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict_proba(data_test)[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### EXTRA TREES #######\n",
    "\n",
    "# Add TREES TF\n",
    "new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA TREES TF\n",
    "new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict_proba(data_train)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "# Add TREES TW\n",
    "new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA TREES TW\n",
    "new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict_proba(data_test_tw)[:,0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### ADABOOST #######\n",
    "\n",
    "# Add adaboost TF\n",
    "new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA adaboost TF\n",
    "new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict_proba(data_train)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "# Add adaboost TW\n",
    "new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA adaboost TW\n",
    "new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict_proba(data_test_tw)[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add created features\n",
    "new_feat_train = csr_vappend(new_feat_train, created_features_train)\n",
    "new_feat_test = csr_vappend(new_feat_test, created_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_ = csr_vappend(data_train, new_feat_train)\n",
    "data_test_ = csr_vappend(data_test, new_feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train__ = scipy.sparse.hstack([data_train_tw, data_train])\n",
    "data_test__ = scipy.sparse.hstack([data_test_tw, data_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Layer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Forest - Score on test_data : ', 0.93711999999999995)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "alg = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, n_jobs = 1)\n",
    "alg.fit(data_train_, label_train)\n",
    "predicted_label_rf = alg.predict(data_test_)\n",
    "\n",
    "print(\"Random Forest - Score on test_data : \", score(label_test, predicted_label_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Num & TOTAL : ', 0.94144000000000005)\n",
      "('Num & Score : ', 1, 0.94272)\n",
      "('Num & Score : ', 2, 0.93584000000000001)\n",
      "('Num & Score : ', 3, 0.94576000000000005)\n",
      "('Num & Score : ', 4, 0.93503999999999998)\n",
      "('Num & Score : ', 5, 0.94543999999999995)\n",
      "('Num & Score : ', 6, 0.93567999999999996)\n",
      "('Num & Score : ', 7, 0.94352000000000003)\n",
      "('Num & Score : ', 8, 0.94352000000000003)\n",
      "('Num & Score : ', 9, 0.94479999999999997)\n",
      "('Num & Score : ', 10, 0.94272)\n",
      "('Num & Score : ', 11, 0.93679999999999997)\n",
      "('Num & Score : ', 12, 0.93776000000000004)\n",
      "('Num & Score : ', 13, 0.94159999999999999)\n",
      "('Num & Score : ', 14, 0.94128000000000001)\n",
      "('Num & Score : ', 15, 0.93903999999999999)\n",
      "('Num & Score : ', 16, 0.94111999999999996)\n",
      "('Num & Score : ', 17, 0.94144000000000005)\n",
      "('Num & Score : ', 18, 0.93984000000000001)\n",
      "('Num & Score : ', 19, 0.94047999999999998)\n",
      "('Num & Score : ', 20, 0.94047999999999998)\n",
      "('Num & Score : ', 21, 0.94111999999999996)\n",
      "('Num & Score : ', 22, 0.94144000000000005)\n",
      "('Num & Score : ', 23, 0.94144000000000005)\n",
      "('Num & Score : ', 24, 0.94144000000000005)\n",
      "('Num & Score : ', 25, 0.94144000000000005)\n",
      "('Num & Score : ', 26, 0.94144000000000005)\n",
      "('Num & Score : ', 27, 0.94144000000000005)\n",
      "('Num & Score : ', 28, 0.94144000000000005)\n",
      "('Num & Score : ', 29, 0.94144000000000005)\n",
      "('Num & Score : ', 30, 0.94144000000000005)\n",
      "('Num & Score : ', 31, 0.94144000000000005)\n",
      "('Num & Score : ', 32, 0.94144000000000005)\n",
      "('Num & Score : ', 33, 0.94144000000000005)\n",
      "('Num & Score : ', 34, 0.94144000000000005)\n",
      "('Num & Score : ', 35, 0.94144000000000005)\n",
      "('Num & Score : ', 36, 0.94144000000000005)\n",
      "('Num & Score : ', 37, 0.94144000000000005)\n",
      "('Num & Score : ', 38, 0.94144000000000005)\n",
      "('Num & Score : ', 39, 0.94144000000000005)\n",
      "('Num & Score : ', 40, 0.94144000000000005)\n",
      "('Num & Score : ', 41, 0.94144000000000005)\n",
      "('Num & Score : ', 42, 0.94144000000000005)\n",
      "('Num & Score : ', 43, 0.94144000000000005)\n"
     ]
    }
   ],
   "source": [
    "train_ = new_feat_train\n",
    "test_ = new_feat_test\n",
    "logreg = LogisticRegression(penalty = 'l2', C = 0.001)\n",
    "logreg.fit(train_, label_train)\n",
    "predicted_label_logreg = logreg.predict(test_)\n",
    "print(\"Num & TOTAL : \", score(label_test, predicted_label_logreg))\n",
    "\n",
    "\n",
    "train_ = new_feat_train[:,1:]\n",
    "test_ = new_feat_test[:,1:]\n",
    "logreg = LogisticRegression(penalty = 'l2', C = 0.001)\n",
    "logreg.fit(train_, label_train)\n",
    "predicted_label_logreg = logreg.predict(test_)\n",
    "print(\"Num & Score : \", 1, score(label_test, predicted_label_logreg))\n",
    "\n",
    "         \n",
    "Num = 1\n",
    "for i in range(2,43):\n",
    "    train_ = scipy.sparse.hstack([new_feat_train[:,0:i-1], new_feat_train[:,i:]])\n",
    "    test_ = scipy.sparse.hstack([new_feat_test[:,0:i-1], new_feat_test[:,i:]])\n",
    "    Num += 1\n",
    "    logreg = LogisticRegression(penalty = 'l2', C = 0.001)\n",
    "    logreg.fit(train_, label_train)\n",
    "    predicted_label_logreg = logreg.predict(test_)\n",
    "    print(\"Num & Score : \", Num, score(label_test, predicted_label_logreg))\n",
    "         \n",
    "         \n",
    "train_ = new_feat_train[:,:43]\n",
    "test_ = new_feat_test[:,:43]\n",
    "logreg = LogisticRegression(penalty = 'l2', C = 0.001)\n",
    "logreg.fit(train_, label_train)\n",
    "predicted_label_logreg = logreg.predict(test_)\n",
    "print(\"Num & Score : \", 43, score(label_test, predicted_label_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Num = 1\n",
    "for i in range(2,43):\n",
    "    train_ = scipy.sparse.hstack([new_feat_train[:,0:i-1], new_feat_train[:,i:]])\n",
    "    test_ = scipy.sparse.hstack([new_feat_test[:,0:i-1], new_feat_test[:,i:]])\n",
    "    Num += 1\n",
    "    logreg = LogisticRegression(penalty = 'l2', C = 0.001)\n",
    "    logreg.fit(train_, label_train)\n",
    "    predicted_label_logreg = logreg.predict(test_)\n",
    "    print(\"Num & Score : \", Num, score(label_test, predicted_label_logreg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 317, 77.69607843137256)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_similarity(predicted_label, predicted_label_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD - Score on test data : ', 0.90383999999999998)\n"
     ]
    }
   ],
   "source": [
    "alg = SGDClassifier(loss='modified_huber', n_iter=100, random_state=0, shuffle=True, penalty='l2')\n",
    "alg.fit( new_feat_train, label_train )\n",
    "predicted_label = alg.predict(new_feat_test)\n",
    "\n",
    "print(\"SGD - Score on test data : \", score(label_test, predicted_label_SGD_TF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTrees - Score on test_data : ', 0.93391999999999997)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "alg = ExtraTreesClassifier(n_estimators=40, max_depth=None, min_samples_split=1, n_jobs = 1)\n",
    "alg.fit(data_train_, label_train)\n",
    "predicted_label = alg.predict(data_test_)\n",
    "\n",
    "print(\"ExtraTrees - Score on test_data : \", score(label_test, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('DecisionTrees - Score on test_data : ', 0.90544000000000002)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "alg = DecisionTreeClassifier(max_depth=None, min_samples_split=1, random_state=0)\n",
    "alg.fit(data_train_, label_train)\n",
    "predicted_label = alg.predict(data_test_)\n",
    "\n",
    "print(\"DecisionTrees - Score on test_data : \", score(label_test, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AdaBoost - Score on test_data : ', 0.90544000000000002)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "alg = AdaBoostClassifier(n_estimators=40)\n",
    "alg.fit(data_train_, label_train)\n",
    "predicted_label = alg.predict(data_test_)\n",
    "\n",
    "print(\"AdaBoost - Score on test_data : \", score(label_test, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-4b53e098a7de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0malg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredicted_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"AdaBoost - Score on test_data : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         \"\"\"\n\u001b[1;32m-> 1498\u001b[1;33m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1499\u001b[0m         \u001b[0mdecisions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_score_to_decision\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.pyc\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1454\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1455\u001b[0m         \"\"\"\n\u001b[1;32m-> 1456\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1457\u001b[0m         \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    369\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[1;32m--> 371\u001b[1;33m                                       force_all_finite)\n\u001b[0m\u001b[0;32m    372\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \"\"\"\n\u001b[0;32m    237\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[0;32m    239\u001b[0m                         \u001b[1;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "alg = GradientBoostingClassifier(n_estimators=100, max_depth=1, random_state=0)\n",
    "alg.fit(data_train_, label_train)\n",
    "predicted_label = alg.predict(data_test_)\n",
    "\n",
    "print(\"AdaBoost - Score on test_data : \", score(label_test, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_prob_lrtw = 1\n",
    "add_prob_lrtf = 1\n",
    "add_prob_sgdtf = 1\n",
    "add_prob_sgdtw = 1\n",
    "add_lab_linearsvc_tf = 1 \n",
    "add_lab_linearsvc_tw = 1\n",
    "add_lab_multinomial_tf = 1\n",
    "add_lab_multinomail_tw = 1\n",
    "add_lab_lrtw = 0\n",
    "add_lab_lrtf = 0\n",
    "add_data_tw = 0\n",
    "\n",
    "if(add_prob_lrtw):\n",
    "    data_train = csr_vappend(data_train, lrtw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "    data_test = csr_vappend(data_test, lrtw.predict_proba(data_test_tw)[:,0].tolist())\n",
    "if(add_lab_lrtw):\n",
    "    data_train = csr_vappend(data_train, lrtw.predict(data_train_tw).tolist())\n",
    "    data_test = csr_vappend(data_test, lrtw.predict(data_test_tw).tolist())    \n",
    "\n",
    "if(add_prob_sgdtf):\n",
    "    data_train = csr_vappend(data_train, sgd_tf.predict(data_train).tolist())\n",
    "    data_test = csr_vappend(data_test, sgd_tf.predict(data_test).tolist())  \n",
    "\n",
    "if(add_prob_sgdtw):\n",
    "    data_train = csr_vappend(data_train, sgd_tw.predict(data_train_tw).tolist())\n",
    "    data_test = csr_vappend(data_test, sgd_tw.predict(data_test_tw).tolist())\n",
    "    \n",
    "if(add_prob_lrtf):\n",
    "    data_train = csr_vappend(data_train, lrtf.predict_proba(data_train[:,0:nb_feat])[:,0].tolist())\n",
    "    data_test = csr_vappend(data_test, lrtf.predict_proba(data_test[:,0:nb_feat])[:,0].tolist())\n",
    "    \n",
    "if(add_lab_lrtw):\n",
    "    data_train = csr_vappend(data_train, lrtf.predict(data_train[:,0:nb_feat]).tolist())\n",
    "    data_test = csr_vappend(data_test, lrtf.predict(data_test[:,0:nb_feat]).tolist())    \n",
    "\n",
    "if(add_data_tw):   \n",
    "    data_train = scipy.sparse.hstack([data_train,data_train_tw])\n",
    "    data_test = scipy.sparse.hstack([data_test,data_test_tw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## adding features IGNORER APRES ICI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csr_vappend(a,b): #b est un vecteur ligne (np.array ou liste) et a est une sparse matrix\n",
    "    if(type(a)!= scipy.sparse.csr.csr_matrix):\n",
    "        a=scipy.sparse.csr_matrix(a)\n",
    "        \n",
    "    if(type(b)== list):\n",
    "        b=np.array([b]).T\n",
    "    if(type(b)!= scipy.sparse.csr.csr_matrix):\n",
    "        b=scipy.sparse.csr_matrix(b)\n",
    "        \n",
    "    return scipy.sparse.hstack([a,b], format ='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6250, 1) (6250, 80000)\n"
     ]
    }
   ],
   "source": [
    "b = lr_tw.predict(data_test_tw).tolist()\n",
    "print np.array([b]).T.shape, data_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train = csr_vappend(data_train, lr_tw.predict(data_train_tw).tolist())\n",
    "data_test = csr_vappend(data_test, lr_tw.predict(data_test_tw).tolist())\n",
    "#data_train = csr_vappend(data_train, alg2.predict(data_train).tolist())\n",
    "#data_test = csr_vappend(data_test, alg2.predict(data_test).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = csr_vappend(data_train, predicted_train_SGD.tolist())\n",
    "data_test = csr_vappend(data_test, predicted_label_SGD.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
