{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import codecs\n",
    "path_baptiste = \"/home/baptiste/Documents/data/train\"\n",
    "path_igor = \"C:/Users/Igor/Documents/Master Data Science/Big Data Analytics/Projet/Data/train\"\n",
    "path_igor_test = \"C:/Users/Igor/Documents/Master Data Science/Big Data Analytics/Projet/Data/test\"\n",
    "path_sofia = \"/Users/Flukmacdesof/data 2/train\"\n",
    "\n",
    "\n",
    "\n",
    "#assumes labelled data ra stored into a positive and negative folder\n",
    "#returns two lists one with the text per file and another with the corresponding class \n",
    "def loadLabeled(path):\n",
    "\n",
    "\trootdirPOS =path+'/pos'\n",
    "\trootdirNEG =path+'/neg'\n",
    "\tdata=[]\n",
    "\tClass=[]\n",
    "\tcount=0\n",
    "\tfor subdir, dirs, files in os.walk(rootdirPOS):\n",
    "\t\t\n",
    "\t\tfor file in files:\n",
    "\t\t\twith codecs.open(rootdirPOS+\"/\"+file, 'r',encoding=\"utf-8\") as content_file:\n",
    "\t\t\t\tcontent = content_file.read() #assume that there are NO \"new line characters\"\n",
    "\t\t\t\tdata.append(content)\n",
    "\ttmpc1=np.ones(len(data))\n",
    "\tfor subdir, dirs, files in os.walk(rootdirNEG):\n",
    "\t\t\n",
    "\t\tfor file in files:\n",
    "\t\t\twith codecs.open(rootdirNEG+\"/\"+file, 'r',encoding=\"utf-8\") as content_file:\n",
    "\t\t\t\tcontent = content_file.read() #assume that there are NO \"new line characters\"\n",
    "\t\t\t\tdata.append(content)\n",
    "\ttmpc0=np.zeros(len(data)-len(tmpc1))\n",
    "\tClass=np.concatenate((tmpc1,tmpc0),axis=0)\n",
    "\treturn data,Class\n",
    "#loads unlabelled data\t\n",
    "#returns two lists\n",
    "#one with the data per file and another with the respective filenames (without the file extension)\n",
    "def loadUnknown(path):\n",
    "\trootdir=path\n",
    "\tdata=[]\n",
    "\tnames=[]\n",
    "\tfor subdir, dirs, files in os.walk(rootdir):\n",
    "\t\tfor file in files:\n",
    "\t\t\twith codecs.open(rootdir+\"/\"+file, 'r', encoding= \"utf-8\") as content_file:\n",
    "\t\t\t\tcontent = content_file.read() #assume that there are NO \"new line characters\"\n",
    "\t\t\t\tdata.append(content)\n",
    "\t\t\t\tnames.append(file.split(\".\")[0])\n",
    "\treturn data,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews, Class = loadLabeled(path_igor)\n",
    "test_test_reviews, names = loadUnknown(path_igor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "english_stemmer=nltk.stem.SnowballStemmer('english')\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "        # Function to convert a document to a sequence of words,\n",
    "        # optionally removing stop words.  Returns a list of words.\n",
    "        #\n",
    "        # 1. Remove HTML\n",
    "        review_text = BeautifulSoup(review).get_text()\n",
    "        #\n",
    "        # 2. Remove non-letters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "        #\n",
    "        # 3. Convert words to lower case and split them\n",
    "        words = review_text.lower().split()\n",
    "        #\n",
    "        # 4. Optionally remove stop words (false by default)\n",
    "        if remove_stopwords:\n",
    "            stops = set(stopwords.words(\"english\"))\n",
    "            words = [w for w in words if not w in stops]\n",
    "\n",
    "        b=[]\n",
    "        stemmer = english_stemmer #PorterStemmer()\n",
    "        for word in words:\n",
    "            b.append(stemmer.stem(word))\n",
    "\n",
    "        # 5. Return a list of words\n",
    "        return(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_reviews, test_reviews, train_label, test_label = train_test_split(reviews, Class, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "clean_train_reviews = []\n",
    "for review in train_reviews:\n",
    "    clean_train_reviews.append( \" \".join( review_to_wordlist( review, remove_stopwords = False )))\n",
    "    \n",
    "clean_test_reviews = []\n",
    "for review in test_reviews:\n",
    "    clean_test_reviews.append( \" \".join( review_to_wordlist( review, remove_stopwords = False )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer( min_df=2, max_df=0.95, max_features = 200000, ngram_range = ( 1, 4 ), sublinear_tf = True )\n",
    "\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "test_data_features = vectorizer.transform( clean_test_reviews )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing dimension...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reducing dimension...\")\n",
    "\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "fselect = SelectKBest(chi2 , k=70000)\n",
    "train_data_features = fselect.fit_transform(train_data_features, train_label)\n",
    "test_data_features = fselect.transform(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model1 = LogisticRegression(penalty = 'l2')\n",
    "model1.fit(train_data_features, train_label)\n",
    "\n",
    "model2 = SGDClassifier(loss='modified_huber', n_iter=5, random_state=0, shuffle=True)\n",
    "model2.fit( train_data_features, train_label )\n",
    "\n",
    "p1 = model1.predict_proba( test_data_features )[:,1]\n",
    "p2 = model2.predict_proba( test_data_features )[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(true_label, predicted_label):\n",
    "    length = len(true_label)\n",
    "    total = 0\n",
    "    for i, label in enumerate(true_label):\n",
    "        if label == predicted_label[i]:\n",
    "            total += 1\n",
    "    return float(total)/float(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.91008\n"
     ]
    }
   ],
   "source": [
    "Cs = np.linspace(0,10, 101)\n",
    "bestC = -1\n",
    "bestScore = 0\n",
    "for C in Cs:\n",
    "    proba = C*p1 + 1.* p2\n",
    "    predicted_label = [1 if p/(1.+C)>0.5 else 0 for p in proba]\n",
    "    if score(test_label, predicted_label) > bestScore:\n",
    "        bestScore = score(test_label, predicted_label)\n",
    "        bestC = C\n",
    "\n",
    "proba = bestC*p1 + 1.* p2\n",
    "predicted_label = [1 if p >0.5 else 0 for p in proba]\n",
    "print(bestC, score(test_label, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91008\n"
     ]
    }
   ],
   "source": [
    "predicted_label = model2.predict(test_data_features)\n",
    "print(score(test_label, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This review is for the extended cut of this movie.<br /><br />I first watched Dragon Lord when I bought it on DVD many years ago. I always liked this movie and you can read some of the more positive reviews of it to get the general idea.<br /><br />That being said. I\\'ve always found the storyline a bit confusing. The movie is, after all, a love story. And it always seemed strange to me that a love story should end with a 20 minute fight scene.<br /><br />Well, in the extended version this is no longer so. The old \"original\" version begins off with a huge barrel-climb/rugby-like sequence which is the new ending sequence in the extended version. The opening sequence is Dragon(Jackie Chan) hanging around his house and pretending to be training and reciting whenever his father is around.<br /><br />Other sequenced have also been shift or prolonged in the extended cut and the story makes a lot more sense when you watch it. The pacing is also better and overall it just works better. It feels more like a love story and doesn\\'t leave you asking questions about why it ends so drastically and dramatically as the regular version does.<br /><br />I suggest everyone who is a Hong-Kong cinema, or just plain Jackie Chan fanatic to get a hold of the extended version and watch the movie the way it was originally intended.(Or at least that\\'s how I think it was intended. Why else would they make it and rearrange some of the scenes) When I was done watching it, I felt like I had watched a completely new Jackie Chan movie although most of the sequences were the same.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_reviews[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this review is for the extend cut of this movi i first watch dragon lord when i bought it on dvd mani year ago i alway like this movi and you can read some of the more posit review of it to get the general idea that be said i ve alway found the storylin a bit confus the movi is after all a love stori and it alway seem strang to me that a love stori should end with a minut fight scene well in the extend version this is no longer so the old origin version begin off with a huge barrel climb rugbi like sequenc which is the new end sequenc in the extend version the open sequenc is dragon jacki chan hang around his hous and pretend to be train and recit whenev his father is around other sequenc have also been shift or prolong in the extend cut and the stori make a lot more sens when you watch it the pace is also better and overal it just work better it feel more like a love stori and doesn t leav you ask question about whi it end so drastic and dramat as the regular version doe i suggest everyon who is a hong kong cinema or just plain jacki chan fanat to get a hold of the extend version and watch the movi the way it was origin intend or at least that s how i think it was intend whi els would they make it and rearrang some of the scene when i was done watch it i felt like i had watch a complet new jacki chan movi although most of the sequenc were the same'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_reviews[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\Anaconda\\lib\\site-packages\\bs4\\__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'review',\n",
       " 'is',\n",
       " 'for',\n",
       " 'the',\n",
       " 'extend',\n",
       " 'cut',\n",
       " 'of',\n",
       " 'this',\n",
       " 'movi',\n",
       " 'i',\n",
       " 'first',\n",
       " 'watch',\n",
       " 'dragon',\n",
       " 'lord',\n",
       " 'when',\n",
       " 'i',\n",
       " 'bought',\n",
       " 'it',\n",
       " 'on',\n",
       " 'dvd',\n",
       " 'mani',\n",
       " 'year',\n",
       " 'ago',\n",
       " 'i',\n",
       " 'alway',\n",
       " 'like',\n",
       " 'this',\n",
       " 'movi',\n",
       " 'and',\n",
       " 'you',\n",
       " 'can',\n",
       " 'read',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'more',\n",
       " 'posit',\n",
       " 'review',\n",
       " 'of',\n",
       " 'it',\n",
       " 'to',\n",
       " 'get',\n",
       " 'the',\n",
       " 'general',\n",
       " 'idea',\n",
       " 'that',\n",
       " 'be',\n",
       " 'said',\n",
       " 'i',\n",
       " 've',\n",
       " 'alway',\n",
       " 'found',\n",
       " 'the',\n",
       " 'storylin',\n",
       " 'a',\n",
       " 'bit',\n",
       " 'confus',\n",
       " 'the',\n",
       " 'movi',\n",
       " 'is',\n",
       " 'after',\n",
       " 'all',\n",
       " 'a',\n",
       " 'love',\n",
       " 'stori',\n",
       " 'and',\n",
       " 'it',\n",
       " 'alway',\n",
       " 'seem',\n",
       " 'strang',\n",
       " 'to',\n",
       " 'me',\n",
       " 'that',\n",
       " 'a',\n",
       " 'love',\n",
       " 'stori',\n",
       " 'should',\n",
       " 'end',\n",
       " 'with',\n",
       " 'a',\n",
       " 'minut',\n",
       " 'fight',\n",
       " 'scene',\n",
       " 'well',\n",
       " 'in',\n",
       " 'the',\n",
       " 'extend',\n",
       " 'version',\n",
       " 'this',\n",
       " 'is',\n",
       " 'no',\n",
       " 'longer',\n",
       " 'so',\n",
       " 'the',\n",
       " 'old',\n",
       " 'origin',\n",
       " 'version',\n",
       " 'begin',\n",
       " 'off',\n",
       " 'with',\n",
       " 'a',\n",
       " 'huge',\n",
       " 'barrel',\n",
       " 'climb',\n",
       " 'rugbi',\n",
       " 'like',\n",
       " 'sequenc',\n",
       " 'which',\n",
       " 'is',\n",
       " 'the',\n",
       " 'new',\n",
       " 'end',\n",
       " 'sequenc',\n",
       " 'in',\n",
       " 'the',\n",
       " 'extend',\n",
       " 'version',\n",
       " 'the',\n",
       " 'open',\n",
       " 'sequenc',\n",
       " 'is',\n",
       " 'dragon',\n",
       " 'jacki',\n",
       " 'chan',\n",
       " 'hang',\n",
       " 'around',\n",
       " 'his',\n",
       " 'hous',\n",
       " 'and',\n",
       " 'pretend',\n",
       " 'to',\n",
       " 'be',\n",
       " 'train',\n",
       " 'and',\n",
       " 'recit',\n",
       " 'whenev',\n",
       " 'his',\n",
       " 'father',\n",
       " 'is',\n",
       " 'around',\n",
       " 'other',\n",
       " 'sequenc',\n",
       " 'have',\n",
       " 'also',\n",
       " 'been',\n",
       " 'shift',\n",
       " 'or',\n",
       " 'prolong',\n",
       " 'in',\n",
       " 'the',\n",
       " 'extend',\n",
       " 'cut',\n",
       " 'and',\n",
       " 'the',\n",
       " 'stori',\n",
       " 'make',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'more',\n",
       " 'sens',\n",
       " 'when',\n",
       " 'you',\n",
       " 'watch',\n",
       " 'it',\n",
       " 'the',\n",
       " 'pace',\n",
       " 'is',\n",
       " 'also',\n",
       " 'better',\n",
       " 'and',\n",
       " 'overal',\n",
       " 'it',\n",
       " 'just',\n",
       " 'work',\n",
       " 'better',\n",
       " 'it',\n",
       " 'feel',\n",
       " 'more',\n",
       " 'like',\n",
       " 'a',\n",
       " 'love',\n",
       " 'stori',\n",
       " 'and',\n",
       " 'doesn',\n",
       " 't',\n",
       " 'leav',\n",
       " 'you',\n",
       " 'ask',\n",
       " 'question',\n",
       " 'about',\n",
       " 'whi',\n",
       " 'it',\n",
       " 'end',\n",
       " 'so',\n",
       " 'drastic',\n",
       " 'and',\n",
       " 'dramat',\n",
       " 'as',\n",
       " 'the',\n",
       " 'regular',\n",
       " 'version',\n",
       " 'doe',\n",
       " 'i',\n",
       " 'suggest',\n",
       " 'everyon',\n",
       " 'who',\n",
       " 'is',\n",
       " 'a',\n",
       " 'hong',\n",
       " 'kong',\n",
       " 'cinema',\n",
       " 'or',\n",
       " 'just',\n",
       " 'plain',\n",
       " 'jacki',\n",
       " 'chan',\n",
       " 'fanat',\n",
       " 'to',\n",
       " 'get',\n",
       " 'a',\n",
       " 'hold',\n",
       " 'of',\n",
       " 'the',\n",
       " 'extend',\n",
       " 'version',\n",
       " 'and',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'movi',\n",
       " 'the',\n",
       " 'way',\n",
       " 'it',\n",
       " 'was',\n",
       " 'origin',\n",
       " 'intend',\n",
       " 'or',\n",
       " 'at',\n",
       " 'least',\n",
       " 'that',\n",
       " 's',\n",
       " 'how',\n",
       " 'i',\n",
       " 'think',\n",
       " 'it',\n",
       " 'was',\n",
       " 'intend',\n",
       " 'whi',\n",
       " 'els',\n",
       " 'would',\n",
       " 'they',\n",
       " 'make',\n",
       " 'it',\n",
       " 'and',\n",
       " 'rearrang',\n",
       " 'some',\n",
       " 'of',\n",
       " 'the',\n",
       " 'scene',\n",
       " 'when',\n",
       " 'i',\n",
       " 'was',\n",
       " 'done',\n",
       " 'watch',\n",
       " 'it',\n",
       " 'i',\n",
       " 'felt',\n",
       " 'like',\n",
       " 'i',\n",
       " 'had',\n",
       " 'watch',\n",
       " 'a',\n",
       " 'complet',\n",
       " 'new',\n",
       " 'jacki',\n",
       " 'chan',\n",
       " 'movi',\n",
       " 'although',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " 'sequenc',\n",
       " 'were',\n",
       " 'the',\n",
       " 'same']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_to_wordlist(train_reviews[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
