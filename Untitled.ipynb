{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import scipy\n",
    "import csv\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.csr_matrix(( loader['data'], loader['indices'], loader['indptr']),\n",
    "                     shape = loader['shape'])\n",
    "        \n",
    "def load_csv(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = '\\n')\n",
    "        array = [float(row[0]) for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_feature_names(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter= '\\n')\n",
    "        array = [row for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_sparse_coo(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.coo_matrix((loader['data'],(loader['row'],loader['col'])),\n",
    "                     shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf- Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_train_tf = load_sparse_csr('bapt_tfidf/data_train.npz')\n",
    "data_train_test_tf = load_sparse_csr('bapt_tfidf/data_test.npz')\n",
    "\n",
    "label_train= load_csv('labels_train_train.csv')\n",
    "label_test = load_csv('labels_train_test.csv')\n",
    "\n",
    "created_feat_train_train = load_sparse_csr('bapt_tfidf/train_new_feat.npz')\n",
    "created_feat_train_test = load_sparse_csr('bapt_tfidf/test_new_feat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "data_train_tf = scipy.sparse.vstack([data_train_train_tf, data_train_test_tf], format ='csr')\n",
    "label = label_train + label_test\n",
    "created_feat = scipy.sparse.vstack([created_feat_train_train, created_feat_train_test], format = 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "data_train_train_tf, data_train_test_tf, label_train, label_test = train_test_split(data_train_tf, label, test_size = 0.25, random_state = 13)\n",
    "created_features_train, created_features_test = train_test_split(created_feat, test_size = 0.25, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18750, 80000)\n"
     ]
    }
   ],
   "source": [
    "nb_feat = 80000\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "fselect = SelectKBest(chi2 , k=nb_feat)\n",
    "data_train = fselect.fit_transform(data_train_train_tf, label_train)\n",
    "data_test = fselect.transform(data_train_test_tf)\n",
    "print data_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_all = [load_sparse_csr('tw_sw{}_all_train_train.npz'.format(k)) for k in range(1,6)]\n",
    "data_test_all = [load_sparse_csr('tw_sw{}_all_train_test.npz'.format(k)) for k in range(1,6)]\n",
    "data_train_sep = [load_sparse_coo('tw_sw{}_train_train.npz'.format(k)) for k in range(1,6)]\n",
    "data_test_sep = [load_sparse_coo('tw_sw{}_train_test.npz'.format(k)) for k in range(1,6)]\n",
    "\n",
    "label_train_tw = load_csv('labels_train_train.csv')\n",
    "label_test_tw = load_csv('labels_train_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "normalizer_all = map(lambda x: MaxAbsScaler().fit(x), data_train_all)\n",
    "normalizer_sep = map(lambda x: MaxAbsScaler().fit(x), data_train_sep)\n",
    "\n",
    "scaler =MaxAbsScaler()\n",
    "scaler.partial_fit(data_test)\n",
    "scaler.partial_fit(data_train)\n",
    "scaler.transform(data_test)\n",
    "scaler.transform(data_train)\n",
    "\n",
    "data_train_all_norm = [normalizer_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_norm = [normalizer_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n",
    "data_train_sep_norm = [normalizer_sep[i].transform(data_train_sep[i]) for i in range(len(data_train_sep))]\n",
    "data_test_sep_norm = [normalizer_sep[i].transform(data_test_sep[i]) for i in range(len(data_test_sep))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 0 0 ..., 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "C:\\Users\\Igor\\Anaconda\\envs\\py27\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 0 0 0 0 0 0 0 0 0] are constant.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "SelectKBest(f_classif , k=data_train_all[0].shape[1]/100).fit(data_train_all[0],label_train_tw)\n",
    "fselect_all = [SelectKBest(f_classif , k=data_train_all[i].shape[1]/100).fit(\n",
    "        data_train_all[i],label_train_tw) for i in range(len(data_train_all))]\n",
    "fselect_sep = [SelectKBest(f_classif , k=data_train_sep[i].shape[1]/100).fit(\n",
    "        data_train_sep[i], label_train_tw) for i in range(len(data_train_sep))]\n",
    "data_train_all_selec = [fselect_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_selec = [fselect_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n",
    "\n",
    "data_train_sep_selec = [fselect_sep[i].transform(data_train_sep[i]) for i in range(len(data_train_sep))]\n",
    "data_test_sep_selec = [fselect_sep[i].transform(data_test_sep[i]) for i in range(len(data_test_sep))]\n",
    "fselect_all_norm = [SelectKBest(f_classif , k=data_train_all_norm[i].shape[1]/100).fit(\n",
    "        data_train_all_norm[i],label_train_tw) for i in range(len(data_train_all_norm))]\n",
    "fselect_sep_norm = [SelectKBest(f_classif , k=data_train_sep[i].shape[1]/100).fit(\n",
    "        data_train_sep_norm[i], label_train_tw) for i in range(len(data_train_sep_norm))]\n",
    "\n",
    "data_train_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_train_all_norm[i]) for i in range(len(data_train_all_norm))]\n",
    "data_test_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_test_all_norm[i]) for i in range(len(data_test_all_norm))]\n",
    "data_train_sep_norm_selec = [fselect_sep_norm[i].transform(\n",
    "        data_train_sep_norm[i]) for i in range(len(data_train_sep_norm))]\n",
    "data_test_sep_norm_selec = [fselect_sep_norm[i].transform(\n",
    "        data_test_sep_norm[i]) for i in range(len(data_test_sep_norm))]\n",
    "\n",
    "data_train_train_tw = data_train_all_norm [3]\n",
    "data_train_test_tw = data_test_all_norm [3]\n",
    "\n",
    "data_train_tw = data_train_tw[:,0:-25]\n",
    "data_test_tw = data_train_tw[:,0:-25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_tw = scipy.sparse.vstack([data_train_train_tw, data_train_test_tw], format ='csr')\n",
    "label_tw = scipy.sparse.vstack([label_train_tw, label_test_tw], format = 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_tw, data_test_tw, label_train, label_test = train_test_split(data_train_tw, label, test_size = 0.25, random_state = 13)\n",
    "label_train_tw, label_test_tw = train_test_split(label_tw, test_size = 0.25, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "def score(true_label, predicted_label):\n",
    "    return 1 - zero_one_loss(true_label,predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVM - Best C & associated score', {'C': 1000.0}, 0.92378666666666664)\n",
      "('SVM - Score on test_data : ', 0.90447999999999995)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(1000, 1500, 10)}\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrtf = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "lrtf = lrtf.fit(data_train, label_train)\n",
    "predicted_label_lrtf = lrtf.predict(data_test)\n",
    "\n",
    "\n",
    "print(\"SVM - Best C & associated score\", lrtf.best_params_, lrtf.best_score_)\n",
    "print(\"SVM - Score on test_data : \", score(label_test, predicted_label_lrtf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cs = {'C': np.linspace(0.4, 1, 20)}\n",
    "\n",
    "lrtw = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "lrtw = lrtw.fit(data_train_tw, label_train_tw)\n",
    "predicted_label_lrtw = lrtw.predict(data_test_tw)\n",
    "\n",
    "print(\"SVM - Best C & associated score\", lrtw.best_params_, lrtw.best_score_)\n",
    "print(\"SVM - Score on test_data : \", score(label_test, predicted_label_lrtw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD - Score on test data : ', 0.90512000000000004)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_tf = SGDClassifier(loss='modified_huber', n_iter=100, random_state=0, shuffle=True, penalty='l2')\n",
    "sgd_tf.fit( data_train, label_train )\n",
    "predicted_label_SGD_TF = sgd_tf.predict(data_test)\n",
    "\n",
    "print(\"SGD - Score on test data : \", score(label_test, predicted_label_SGD_TF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD - Score on test data : ', 0.86895999999999995)\n"
     ]
    }
   ],
   "source": [
    "sgd_tw = SGDClassifier(loss='modified_huber', n_iter=100, random_state=0, shuffle=True, penalty='l2')\n",
    "sgd_tw.fit( data_train_tw, label_train )\n",
    "predicted_label_SGD_TW = sgd_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"SGD - Score on test data : \", score(label_test, predicted_label_SGD_TW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear SVC - Best C & associated score', {'C': 3.0}, 0.92517333333333329)\n",
      "('Linear svc  - Score on test_data : ', 0.90464)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Cs = {'C': np.linspace(3, 5, 10)}\n",
    "svc_tf = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "svc_tf.fit(data_train, label_train)\n",
    "predicted_label_SVC_TF = svc_tf.predict(data_test)\n",
    "\n",
    "print(\"Linear SVC - Best C & associated score\", svc_tf.best_params_, svc_tf.best_score_)\n",
    "print(\"Linear svc  - Score on test_data : \", score(predicted_label_SVC_TF, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear SVC - Best C & associated score', {'C': 0.032500000000000001}, 0.87551999999999996)\n",
      "('linear svc  - Score on test_data : ', 0.88624000000000003)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(0.01, 0.1, 5)}\n",
    "svc_tw = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "svc_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_SVC_TW = svc_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"Linear SVC - Best C & associated score\", svc_tw.best_params_, svc_tw.best_score_)\n",
    "print(\"linear svc  - Score on test_data : \", score(predicted_label_SVC_TW, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Multinomial - Best alpha & associated score', {'alpha': 0.00029999999999999997}, 0.95317333333333332)\n",
      "('MNB  - Score on test_data : ', 0.88192000000000004)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "alphas = {'alpha': np.linspace(0.0001, 0.001, 10)}\n",
    "multinom_tf = GridSearchCV(MultinomialNB(), alphas, n_jobs = 1)\n",
    "multinom_tf.fit(data_train, label_train)\n",
    "predicted_label_MN_TF = multinom_tf.predict(data_test)\n",
    "\n",
    "print(\"Multinomial - Best alpha & associated score\", multinom_tf.best_params_, multinom_tf.best_score_)\n",
    "print(\"MNB  - Score on test_data : \", score(predicted_label_MN_TF, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTrees - Score on test_data : ', 0.84896000000000005)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extratrees_tf = ExtraTreesClassifier(n_estimators=40, max_depth=None, min_samples_split=1, random_state=0, n_jobs = 1)\n",
    "extratrees_tf.fit(data_train, label_train)\n",
    "predicted_label_extratrees_tf = extratrees_tf.predict(data_test)\n",
    "\n",
    "print(\"ExtraTrees - Score on test_data : \", score(label_test, predicted_label_extratrees_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTrees - Score on test_data : ', 0.82879999999999998)\n"
     ]
    }
   ],
   "source": [
    "extratrees_tw = ExtraTreesClassifier(n_estimators=40, max_depth=None, min_samples_split=1, random_state=0, n_jobs = 1)\n",
    "extratrees_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_extratrees_tw = extratrees_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"ExtraTrees - Score on test_data : \", score(label_test, predicted_label_extratrees_tw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AdaBoost - Score on test_data : ', 0.78879999999999995)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_tf = AdaBoostClassifier(n_estimators=40)\n",
    "adaboost_tf.fit(data_train, label_train)\n",
    "predicted_label_adaboost_tf = adaboost_tf.predict(data_test)\n",
    "\n",
    "print(\"AdaBoost - Score on test_data : \", score(label_test, predicted_label_adaboost_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AdaBoost - Score on test_data : ', 0.79488000000000003)\n"
     ]
    }
   ],
   "source": [
    "adaboost_tw = AdaBoostClassifier(n_estimators=40)\n",
    "adaboost_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_adaboost_tw = adaboost_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"AdaBoost - Score on test_data : \", score(label_test, predicted_label_adaboost_tw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_similarity(l1, l2):#\n",
    "    ref_diff =0\n",
    "    all_diff =0\n",
    "\n",
    "    for i, label in enumerate(l1):\n",
    "        if(label != label_test[i]):\n",
    "            ref_diff+=1\n",
    "            if(label_test[i] != l2[i]):\n",
    "                all_diff+=1\n",
    "    return ref_diff, all_diff, float(all_diff)/ref_diff *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(597, 72, 12.060301507537687) lrtf sgd_tw\n",
      "(597, 295, 49.413735343383586) lrtf lrtw\n",
      "(597, 69, 11.557788944723619) lrtf svc_tw\n",
      "(597, 118, 19.765494137353436) lrtf adaboost_tw\n",
      "(597, 92, 15.41038525963149) lrtf extratrees_tw\n",
      "(596, 71, 11.912751677852349) svc_tf sgd_tw\n",
      "(596, 292, 48.99328859060403) svc_tf lrtw\n",
      "(596, 67, 11.241610738255034) svc_tf svc_tw\n",
      "(596, 117, 19.630872483221477) svc_tf adaboost_tw\n",
      "(596, 94, 15.771812080536913) svc_tf extratrees_tw\n",
      "(944, 126, 13.347457627118645) extratrees_tf sgd_tw\n",
      "(944, 470, 49.78813559322034) extratrees_tf lrtw\n",
      "(944, 110, 11.652542372881355) extratrees_tf svc_tw\n",
      "(944, 189, 20.021186440677965) extratrees_tf adaboost_tw\n",
      "(944, 157, 16.63135593220339) extratrees_tf extratrees_tw\n",
      "(1320, 175, 13.257575757575758) adaboost_tf sgd_tw\n",
      "(1320, 649, 49.166666666666664) adaboost_tf lrtw\n",
      "(1320, 156, 11.818181818181818) adaboost_tf svc_tw\n",
      "(1320, 257, 19.46969696969697) adaboost_tf adaboost_tw\n",
      "(1320, 241, 18.257575757575758) adaboost_tf extratrees_tw\n",
      "(738, 93, 12.601626016260163) multinomial_tf sgd_tw\n",
      "(738, 365, 49.457994579945805) multinomial_tf lrtw\n",
      "(738, 85, 11.517615176151761) multinomial_tf svc_tw\n",
      "(738, 154, 20.867208672086722) multinomial_tf adaboost_tw\n",
      "(738, 128, 17.344173441734416) multinomial_tf extratrees_tw\n",
      "(593, 72, 12.141652613827993) sgd_tf sgd_tw\n",
      "(593, 285, 48.06070826306914) sgd_tf lrtw\n",
      "(593, 69, 11.63575042158516) sgd_tf svc_tw\n",
      "(593, 115, 19.392917369308602) sgd_tf adaboost_tw\n",
      "(593, 99, 16.694772344013494) sgd_tf extratrees_tw\n",
      "------------------------------------------\n",
      "(597, 579, 96.98492462311557) lrtf svc_tf\n",
      "(597, 378, 63.31658291457286) lrtf extratrees_tf\n",
      "(597, 364, 60.971524288107204) lrtf adaboost_tf\n",
      "(597, 379, 63.484087102177554) lrtf multinomial_tf\n",
      "(597, 510, 85.42713567839196) lrtf sgd_tf\n",
      "(596, 579, 97.14765100671141) svc_tf lrtf\n",
      "(596, 382, 64.09395973154362) svc_tf extratrees_tf\n",
      "(596, 362, 60.738255033557046) svc_tf adaboost_tf\n",
      "(596, 380, 63.758389261744966) svc_tf multinomial_tf\n",
      "(596, 514, 86.24161073825503) svc_tf sgd_tf\n",
      "(944, 378, 40.04237288135593) extratrees_tf lrtf\n",
      "(944, 382, 40.46610169491525) extratrees_tf svc_tf\n",
      "(944, 545, 57.733050847457626) extratrees_tf adaboost_tf\n",
      "(944, 409, 43.32627118644068) extratrees_tf multinomial_tf\n",
      "(944, 412, 43.64406779661017) extratrees_tf sgd_tf\n",
      "(1320, 364, 27.575757575757574) adaboost_tf lrtf\n",
      "(1320, 362, 27.424242424242422) adaboost_tf svc_tf\n",
      "(1320, 545, 41.28787878787879) adaboost_tf extratrees_tf\n",
      "(1320, 359, 27.196969696969695) adaboost_tf multinomial_tf\n",
      "(1320, 380, 28.78787878787879) adaboost_tf sgd_tf\n",
      "(738, 379, 51.355013550135496) multinomial_tf lrtf\n",
      "(738, 380, 51.490514905149055) multinomial_tf svc_tf\n",
      "(738, 409, 55.420054200542005) multinomial_tf extratrees_tf\n",
      "(738, 359, 48.6449864498645) multinomial_tf adaboost_tf\n",
      "(738, 405, 54.87804878048781) multinomial_tf sgd_tf\n",
      "(593, 510, 86.00337268128162) sgd_tf lrtf\n",
      "(593, 514, 86.6779089376054) sgd_tf svc_tf\n",
      "(593, 412, 69.47723440134908) sgd_tf extratrees_tf\n",
      "(593, 380, 64.08094435075886) sgd_tf adaboost_tf\n",
      "(593, 405, 68.29679595278246) sgd_tf multinomial_tf\n",
      "------------------------------------------\n",
      "(819, 422, 51.52625152625152) sgd_tw lrtw\n",
      "(819, 593, 72.4053724053724) sgd_tw svc_tw\n",
      "(819, 395, 48.22954822954823) sgd_tw adaboost_tw\n",
      "(819, 441, 53.84615384615385) sgd_tw extratrees_tw\n",
      "(3125, 422, 13.504) lrtw sgd_tw\n",
      "(3125, 367, 11.744) lrtw svc_tw\n",
      "(3125, 626, 20.032) lrtw adaboost_tw\n",
      "(3125, 526, 16.832) lrtw extratrees_tw\n",
      "(711, 593, 83.40365682137833) svc_tw sgd_tw\n",
      "(711, 367, 51.61744022503516) svc_tw lrtw\n",
      "(711, 407, 57.24331926863573) svc_tw adaboost_tw\n",
      "(711, 467, 65.68213783403657) svc_tw extratrees_tw\n",
      "(1282, 395, 30.81123244929797) adaboost_tw sgd_tw\n",
      "(1282, 626, 48.829953198127924) adaboost_tw lrtw\n",
      "(1282, 407, 31.747269890795632) adaboost_tw svc_tw\n",
      "(1282, 520, 40.5616224648986) adaboost_tw extratrees_tw\n",
      "(1070, 441, 41.21495327102804) extratrees_tw sgd_tw\n",
      "(1070, 526, 49.1588785046729) extratrees_tw lrtw\n",
      "(1070, 467, 43.64485981308411) extratrees_tw svc_tw\n",
      "(1070, 520, 48.598130841121495) extratrees_tw adaboost_tw\n"
     ]
    }
   ],
   "source": [
    "predicted_label_TF = {\"lrtf\": predicted_label_lrtf, \n",
    "                      \"sgd_tf\" : predicted_label_SGD_TF, \n",
    "                      \"svc_tf\" :predicted_label_SVC_TF,\n",
    "                      \"multinomial_tf\" : predicted_label_MN_TF,\n",
    "                      \"extratrees_tf\" : predicted_label_extratrees_tf,\n",
    "                      \"adaboost_tf\" : predicted_label_adaboost_tf,\n",
    "                      }\n",
    "                      \n",
    "predicted_label_TW = {\"lrtw\": predicted_label_lrtw, \n",
    "                      \"sgd_tw\" : predicted_label_SGD_TW, \n",
    "                      \"svc_tw\" :predicted_label_SVC_TW,\n",
    "                      \"extratrees_tw\" : predicted_label_extratrees_tw,\n",
    "                      \"adaboost_tw\" : predicted_label_adaboost_tw,\n",
    "                      }\n",
    "\n",
    "for tfkey, tfvalue in predicted_label_TF.items():\n",
    "    for twkey, twvalue in predicted_label_TW.items():\n",
    "        print error_similarity(tfvalue,twvalue), tfkey, twkey\n",
    "\n",
    "print '------------------------------------------'\n",
    "\n",
    "for tfkey, tfvalue in predicted_label_TF.items():\n",
    "    for tfkey2, tfvalue2 in predicted_label_TF.items():\n",
    "        if tfkey != tfkey2:\n",
    "            print error_similarity(tfvalue,tfvalue2), tfkey, tfkey2\n",
    "            \n",
    "print '------------------------------------------'\n",
    "\n",
    "for twkey, twvalue in predicted_label_TW.items():\n",
    "    for twkey2, twvalue2 in predicted_label_TW.items():\n",
    "        if twkey != twkey2:\n",
    "            print error_similarity(twvalue,twvalue2), twkey, twkey2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def csr_vappend(a,b): #b est un vecteur ligne (np.array ou liste) et a est une sparse matrix\n",
    "    if(type(a)== list):\n",
    "        a=np.array([a]).T\n",
    "    if(type(b)== list):\n",
    "        b=np.array([b]).T\n",
    "    if(type(a)!= scipy.sparse.csr.csr_matrix):\n",
    "        a=scipy.sparse.csr_matrix(a)\n",
    "    if(type(b)!= scipy.sparse.csr.csr_matrix):\n",
    "        b=scipy.sparse.csr_matrix(b)\n",
    "        \n",
    "    return scipy.sparse.hstack([a,b], format ='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### LOG REG ######\n",
    "\n",
    "# Add PROBA Logistic Regression TF\n",
    "new_feat_train = lrtw.predict_proba(data_train_tw)[:,0].tolist()\n",
    "new_feat_test = lrtw.predict_proba(data_test_tw)[:,0].tolist()\n",
    "\n",
    "# Add PROBA Logistic Regression TW\n",
    "new_feat_train = csr_vappend(new_feat_train, lrtf.predict_proba(data_train)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, lrtf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "###### SGD ########\n",
    "\n",
    "# Add SGD TF\n",
    "new_feat_train = csr_vappend(new_feat_train, sgd_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, sgd_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add SGD TW\n",
    "new_feat_train = csr_vappend(new_feat_train, sgd_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, sgd_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### LINEAR SVC #######\n",
    "\n",
    "# Add Linear SVC TF\n",
    "new_feat_train = csr_vappend(new_feat_train, svc_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, svc_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add Linear SVC TW\n",
    "new_feat_train = csr_vappend(new_feat_train, svc_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, svc_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### MULTINOMIAL NAIVE BAYES ######\n",
    "\n",
    "# Add Multinomial TF\n",
    "new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA Multinomial TF\n",
    "new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict_proba(data_train)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict_proba(data_test)[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### EXTRA TREES #######\n",
    "\n",
    "# Add TREES TF\n",
    "new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA TREES TF\n",
    "new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict_proba(data_train)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "# Add TREES TW\n",
    "new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA TREES TW\n",
    "new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict_proba(data_test_tw)[:,0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### ADABOOST #######\n",
    "\n",
    "# Add adaboost TF\n",
    "new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict(data_train).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA adaboost TF\n",
    "new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict_proba(data_train)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "# Add adaboost TW\n",
    "new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA adaboost TW\n",
    "new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict_proba(data_test_tw)[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add created features\n",
    "new_feat_train = csr_vappend(new_feat_train, created_features_train)\n",
    "new_feat_test = csr_vappend(new_feat_test, created_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_ = csr_vappend(data_train, new_feat_train)\n",
    "data_test_ = csr_vappend(data_test, new_feat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train__ = scipy.sparse.hstack([data_train_tw, data_train])\n",
    "data_test__ = scipy.sparse.hstack([data_test_tw, data_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Layer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "alg = RandomForestClassifier(n_estimators=100, min_samples_split=2, min_samples_leaf=1, n_jobs = 1)\n",
    "alg.fit(data_train_, label_train)\n",
    "predicted_label_rf = alg.predict(data_test_)\n",
    "\n",
    "print(\"Random Forest - Score on test_data : \", score(label_test, predicted_label_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Num & TOTAL : ', 0.94672000000000001)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty = 'l2', C = 0.01)\n",
    "logreg.fit(new_feat_train, label_train)\n",
    "predicted_label_logreg = logreg.predict(new_feat_test)\n",
    "print(\"Num & TOTAL : \", score(label_test, predicted_label_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = new_feat_train[:,0]\n",
    "test = new_feat_test[:,0]\n",
    "\n",
    "for i in range(1,43):\n",
    "    train_draft = scipy.sparse.hstack([train, new_feat_train[:,i]])\n",
    "    test_draft = scipy.sparse.hstack([test, new_feat_test[:,i]])\n",
    "    \n",
    "    logreg = LogisticRegression(penalty = 'l2', C = 0.01)\n",
    "    logreg.fit(train_draft, label_train)\n",
    "    predicted_label_logreg = logreg.predict(test_draft)\n",
    "    print(\"Num & TOTAL : \", score(label_test, predicted_label_logreg))\n",
    "    new_feat_train = \n",
    "    new_feat_test = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
