{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import scipy\n",
    "import csv\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.csr_matrix(( loader['data'], loader['indices'], loader['indptr']),\n",
    "                     shape = loader['shape'])\n",
    "        \n",
    "def load_csv(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = '\\n')\n",
    "        array = [float(row[0]) for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_feature_names(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter= '\\n')\n",
    "        array = [row for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_sparse_coo(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.coo_matrix((loader['data'],(loader['row'],loader['col'])),\n",
    "                     shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "def score(true_label, predicted_label):\n",
    "    return 1 - zero_one_loss(true_label,predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"bapt_tfidf/\"\n",
    "data_train_train_tf = load_sparse_csr(path+'data_train.npz')\n",
    "data_train_test_tf = load_sparse_csr(path+'data_test.npz')\n",
    "data_test = load_sparse_csr(path+'data_test_test.npz')\n",
    "\n",
    "\n",
    "label_train = load_csv(path+'label_train.csv')\n",
    "label_test = load_csv(path+'label_test.csv')\n",
    "features_names = load_feature_names('data/feature_names.csv')\n",
    "\n",
    "created_feat_train_train = load_sparse_csr(path+'train_new_feat.npz')\n",
    "created_feat_train_test = load_sparse_csr(path+'test_new_feat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "data_train = scipy.sparse.vstack([data_train_train_tf, data_train_test_tf], format ='csr')\n",
    "label_train = label_train + label_test\n",
    "created_feat = scipy.sparse.vstack([created_feat_train_train, created_feat_train_test], format = 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80000) (25000, 80000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:165: RuntimeWarning: invalid value encountered in divide\n",
      "  chisq /= f_exp\n"
     ]
    }
   ],
   "source": [
    "nb_feat = 80000\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "fselect = SelectKBest(chi2 , k=nb_feat)\n",
    "data_train = fselect.fit_transform(data_train, label_train)\n",
    "data_test = fselect.transform(data_test)\n",
    "print data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_all = [load_sparse_csr('tw_sw{}_all_train.npz'.format(k)) for k in range(1,5)]\n",
    "data_test_all = [load_sparse_csr('tw_sw{}_all_test.npz'.format(k)) for k in range(1,5)]\n",
    "\n",
    "label_train_tw = load_csv('labels_train_train.csv')\n",
    "label_test_tw = load_csv('labels_train_test.csv')\n",
    "label_train_tw = label_train_tw +label_test_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 99627)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_all[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "normalizer_all = map(lambda x: MaxAbsScaler().fit(x), data_train_all)\n",
    "\n",
    "scaler =MaxAbsScaler()\n",
    "scaler.partial_fit(data_test)\n",
    "scaler.partial_fit(data_train)\n",
    "scaler.transform(data_test)\n",
    "scaler.transform(data_train)\n",
    "\n",
    "data_train_all_norm = [normalizer_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_norm = [normalizer_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [0 0 0 ..., 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "SelectKBest(f_classif , k=data_train_all[0].shape[1]/100).fit(data_train_all[0],label_train_tw)\n",
    "fselect_all = [SelectKBest(f_classif , k=data_train_all[i].shape[1]/100).fit(\n",
    "        data_train_all[i],label_train_tw) for i in range(len(data_train_all))]\n",
    "data_train_all_selec = [fselect_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_selec = [fselect_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n",
    "\n",
    "fselect_all_norm = [SelectKBest(f_classif , k=data_train_all_norm[i].shape[1]/100).fit(\n",
    "        data_train_all_norm[i],label_train_tw) for i in range(len(data_train_all_norm))]\n",
    "\n",
    "data_train_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_train_all_norm[i]) for i in range(len(data_train_all_norm))]\n",
    "data_test_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_test_all_norm[i]) for i in range(len(data_test_all_norm))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_tw = data_train_all_norm [3]\n",
    "data_test_tw = data_test_all_norm [3]\n",
    "\n",
    "data_train_tw = data_train_tw[:,0:-25]\n",
    "data_test_tw = data_test_tw[:,0:-25]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 99602) (25000, 99602)\n"
     ]
    }
   ],
   "source": [
    "print data_train_tw.shape, data_test_tw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "- Adding the proba (instead of the label) is better for the final predition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVM - Best C & associated score', {'C': 1222.2222222222222}, 0.92352000000000001)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(1000, 1500, 10)}\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrtf = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "lrtf = lrtf.fit(data_train, label_train)\n",
    "predicted_label_lrtf = lrtf.predict(data_test)\n",
    "\n",
    "\n",
    "print(\"SVM - Best C & associated score\", lrtf.best_params_, lrtf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVM - Best C & associated score', {'C': 0.90526315789473688}, 0.49715999999999999)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(0.4, 1, 20)}\n",
    "\n",
    "lrtw = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "lrtw = lrtw.fit(data_train_tw, label_train_tw)\n",
    "predicted_label_lrtw = lrtw.predict(data_test_tw)\n",
    "\n",
    "print(\"SVM - Best C & associated score\", lrtw.best_params_, lrtw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier\n",
    "- Impossible to predict a proba, just labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD - Score on test data : ', 0.90383999999999998)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_tf = SGDClassifier(loss='modified_huber', n_iter=100, random_state=0, shuffle=True, penalty='l2')\n",
    "sgd_tf.fit( data_train, label_train )\n",
    "predicted_label_SGD_TF = sgd_tf.predict(data_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD - Score on test data : ', 0.86528000000000005)\n"
     ]
    }
   ],
   "source": [
    "sgd_tw = SGDClassifier(loss='modified_huber', n_iter=100, random_state=0, shuffle=True, penalty='l2')\n",
    "sgd_tw.fit( data_train_tw, label_train )\n",
    "predicted_label_SGD_TW = sgd_tw.predict(data_test_tw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC\n",
    "- Do not predict proba, only labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear SVC - Best C & associated score', {'C': 4.333333333333333}, 0.92458666666666667)\n",
      "('Linear svc  - Score on test_data : ', 0.90527999999999997)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Cs = {'C': np.linspace(3, 5, 10)}\n",
    "svc_tf = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "svc_tf.fit(data_train, label_train)\n",
    "predicted_label_SVC_TF = svc_tf.predict(data_test)\n",
    "\n",
    "print(\"Linear SVC - Best C & associated score\", svc_tf.best_params_, svc_tf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear SVC - Best C & associated score', {'C': 0.055000000000000007}, 0.87648000000000004)\n",
      "('linear svc  - Score on test_data : ', 0.88016000000000005)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(0.01, 0.1, 5)}\n",
    "svc_tw = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = 1)\n",
    "svc_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_SVC_TW = svc_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"Linear SVC - Best C & associated score\", svc_tw.best_params_, svc_tw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n",
    "- Able to return the label, the proba, and the log_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Multinomial - Best alpha & associated score', {'alpha': 0.00029999999999999997}, 0.95413333333333339)\n",
      "('MNB  - Score on test_data : ', 0.88736000000000004)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "alphas = {'alpha': np.linspace(0.0001, 0.001, 10)}\n",
    "multinom_tf = GridSearchCV(MultinomialNB(), alphas, n_jobs = 1)\n",
    "multinom_tf.fit(data_train, label_train)\n",
    "predicted_label_MN_TF = multinom_tf.predict(data_test)\n",
    "\n",
    "print(\"Multinomial - Best alpha & associated score\", multinom_tf.best_params_, multinom_tf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTrees\n",
    "- Can predict label, proba AND log proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTrees - Score on test_data : ', 0.84192)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extratrees_tf = ExtraTreesClassifier(n_estimators=40, max_depth=None, min_samples_split=1, random_state=0, n_jobs = 1)\n",
    "extratrees_tf.fit(data_train, label_train)\n",
    "predicted_label_extratrees_tf = extratrees_tf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTrees - Score on test_data : ', 0.83199999999999996)\n"
     ]
    }
   ],
   "source": [
    "extratrees_tw = ExtraTreesClassifier(n_estimators=40, max_depth=None, min_samples_split=1, random_state=0, n_jobs = 1)\n",
    "extratrees_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_extratrees_tw = extratrees_tw.predict(data_test_tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "- Can predict label, proba AND log proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AdaBoost - Score on test_data : ', 0.78895999999999999)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_tf = AdaBoostClassifier(n_estimators=40)\n",
    "adaboost_tf.fit(data_train, label_train)\n",
    "predicted_label_adaboost_tf = adaboost_tf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AdaBoost - Score on test_data : ', 0.78847999999999996)\n"
     ]
    }
   ],
   "source": [
    "adaboost_tw = AdaBoostClassifier(n_estimators=40)\n",
    "adaboost_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_adaboost_tw = adaboost_tw.predict(data_test_tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the difference in predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_similarity(l1, l2):#\n",
    "    ref_diff =0\n",
    "    all_diff =0\n",
    "\n",
    "    for i, label in enumerate(l1):\n",
    "        if(label != label_test[i]):\n",
    "            ref_diff+=1\n",
    "            if(label_test[i] != l2[i]):\n",
    "                all_diff+=1\n",
    "    return ref_diff, all_diff, float(all_diff)/ref_diff *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(591, 76, 12.859560067681894) lrtf sgd_tw\n",
      "(591, 68, 11.505922165820643) lrtf lrtw\n",
      "(591, 69, 11.6751269035533) lrtf svc_tw\n",
      "(591, 135, 22.84263959390863) lrtf adaboost_tw\n",
      "(591, 106, 17.93570219966159) lrtf extratrees_tw\n",
      "(592, 72, 12.162162162162163) svc_tf sgd_tw\n",
      "(592, 64, 10.81081081081081) svc_tf lrtw\n",
      "(592, 65, 10.97972972972973) svc_tf svc_tw\n",
      "(592, 137, 23.14189189189189) svc_tf adaboost_tw\n",
      "(592, 106, 17.905405405405407) svc_tf extratrees_tw\n",
      "(988, 122, 12.348178137651821) extratrees_tf sgd_tw\n",
      "(988, 107, 10.82995951417004) extratrees_tf lrtw\n",
      "(988, 111, 11.234817813765183) extratrees_tf svc_tw\n",
      "(988, 208, 21.052631578947366) extratrees_tf adaboost_tw\n",
      "(988, 161, 16.295546558704455) extratrees_tf extratrees_tw\n",
      "(1319, 160, 12.130401819560273) adaboost_tf sgd_tw\n",
      "(1319, 144, 10.917361637604246) adaboost_tf lrtw\n",
      "(1319, 146, 11.06899166034875) adaboost_tf svc_tw\n",
      "(1319, 270, 20.47005307050796) adaboost_tf adaboost_tw\n",
      "(1319, 203, 15.390447308567095) adaboost_tf extratrees_tw\n",
      "(704, 91, 12.926136363636365) multinomial_tf sgd_tw\n",
      "(704, 79, 11.221590909090908) multinomial_tf lrtw\n",
      "(704, 83, 11.789772727272728) multinomial_tf svc_tw\n",
      "(704, 155, 22.017045454545457) multinomial_tf adaboost_tw\n",
      "(704, 115, 16.335227272727273) multinomial_tf extratrees_tw\n",
      "(601, 72, 11.980033277870216) sgd_tf sgd_tw\n",
      "(601, 64, 10.64891846921797) sgd_tf lrtw\n",
      "(601, 64, 10.64891846921797) sgd_tf svc_tw\n",
      "(601, 133, 22.129783693843592) sgd_tf adaboost_tw\n",
      "(601, 100, 16.638935108153078) sgd_tf extratrees_tw\n",
      "------------------------------------------\n",
      "(591, 575, 97.29272419627749) lrtf svc_tf\n",
      "(591, 395, 66.83587140439933) lrtf extratrees_tf\n",
      "(591, 355, 60.06768189509306) lrtf adaboost_tf\n",
      "(591, 350, 59.22165820642979) lrtf multinomial_tf\n",
      "(591, 504, 85.27918781725889) lrtf sgd_tf\n",
      "(592, 575, 97.12837837837837) svc_tf lrtf\n",
      "(592, 388, 65.54054054054053) svc_tf extratrees_tf\n",
      "(592, 353, 59.62837837837838) svc_tf adaboost_tf\n",
      "(592, 346, 58.445945945945944) svc_tf multinomial_tf\n",
      "(592, 499, 84.29054054054053) svc_tf sgd_tf\n",
      "(988, 395, 39.979757085020246) extratrees_tf lrtf\n",
      "(988, 388, 39.27125506072874) extratrees_tf svc_tf\n",
      "(988, 565, 57.18623481781376) extratrees_tf adaboost_tf\n",
      "(988, 404, 40.89068825910931) extratrees_tf multinomial_tf\n",
      "(988, 445, 45.040485829959515) extratrees_tf sgd_tf\n",
      "(1319, 355, 26.914329037149354) adaboost_tf lrtf\n",
      "(1319, 353, 26.762699014404852) adaboost_tf svc_tf\n",
      "(1319, 565, 42.835481425322214) adaboost_tf extratrees_tf\n",
      "(1319, 374, 28.354814253222138) adaboost_tf multinomial_tf\n",
      "(1319, 392, 29.71948445792267) adaboost_tf sgd_tf\n",
      "(704, 350, 49.715909090909086) multinomial_tf lrtf\n",
      "(704, 346, 49.14772727272727) multinomial_tf svc_tf\n",
      "(704, 404, 57.38636363636363) multinomial_tf extratrees_tf\n",
      "(704, 374, 53.125) multinomial_tf adaboost_tf\n",
      "(704, 381, 54.11931818181818) multinomial_tf sgd_tf\n",
      "(601, 504, 83.86023294509151) sgd_tf lrtf\n",
      "(601, 499, 83.02828618968387) sgd_tf svc_tf\n",
      "(601, 445, 74.04326123128119) sgd_tf extratrees_tf\n",
      "(601, 392, 65.22462562396007) sgd_tf adaboost_tf\n",
      "(601, 381, 63.394342762063225) sgd_tf multinomial_tf\n",
      "------------------------------------------\n",
      "(842, 633, 75.17814726840855) sgd_tw lrtw\n",
      "(842, 668, 79.33491686460808) sgd_tw svc_tw\n",
      "(842, 458, 54.39429928741093) sgd_tw adaboost_tw\n",
      "(842, 457, 54.27553444180523) sgd_tw extratrees_tw\n",
      "(750, 633, 84.39999999999999) lrtw sgd_tw\n",
      "(750, 706, 94.13333333333334) lrtw svc_tw\n",
      "(750, 448, 59.73333333333334) lrtw adaboost_tw\n",
      "(750, 489, 65.2) lrtw extratrees_tw\n",
      "(749, 668, 89.18558077436583) svc_tw sgd_tw\n",
      "(749, 706, 94.25901201602136) svc_tw lrtw\n",
      "(749, 448, 59.813084112149525) svc_tw adaboost_tw\n",
      "(749, 475, 63.417890520694264) svc_tw extratrees_tw\n",
      "(1322, 458, 34.64447806354009) adaboost_tw sgd_tw\n",
      "(1322, 448, 33.88804841149773) adaboost_tw lrtw\n",
      "(1322, 448, 33.88804841149773) adaboost_tw svc_tw\n",
      "(1322, 528, 39.93948562783661) adaboost_tw extratrees_tw\n",
      "(1050, 457, 43.523809523809526) extratrees_tw sgd_tw\n",
      "(1050, 489, 46.57142857142857) extratrees_tw lrtw\n",
      "(1050, 475, 45.23809523809524) extratrees_tw svc_tw\n",
      "(1050, 528, 50.28571428571429) extratrees_tw adaboost_tw\n"
     ]
    }
   ],
   "source": [
    "predicted_label_TF = {\"lrtf\": predicted_label_lrtf, \n",
    "                      \"sgd_tf\" : predicted_label_SGD_TF, \n",
    "                      \"svc_tf\" :predicted_label_SVC_TF,\n",
    "                      \"multinomial_tf\" : predicted_label_MN_TF,\n",
    "                      \"extratrees_tf\" : predicted_label_extratrees_tf,\n",
    "                      \"adaboost_tf\" : predicted_label_adaboost_tf,\n",
    "                      }\n",
    "                      \n",
    "predicted_label_TW = {\"lrtw\": predicted_label_lrtw, \n",
    "                      \"sgd_tw\" : predicted_label_SGD_TW, \n",
    "                      \"svc_tw\" :predicted_label_SVC_TW,\n",
    "                      \"extratrees_tw\" : predicted_label_extratrees_tw,\n",
    "                      \"adaboost_tw\" : predicted_label_adaboost_tw,\n",
    "                      }\n",
    "\n",
    "for tfkey, tfvalue in predicted_label_TF.items():\n",
    "    for twkey, twvalue in predicted_label_TW.items():\n",
    "        print error_similarity(tfvalue,twvalue), tfkey, twkey\n",
    "\n",
    "print '------------------------------------------'\n",
    "\n",
    "for tfkey, tfvalue in predicted_label_TF.items():\n",
    "    for tfkey2, tfvalue2 in predicted_label_TF.items():\n",
    "        if tfkey != tfkey2:\n",
    "            print error_similarity(tfvalue,tfvalue2), tfkey, tfkey2\n",
    "            \n",
    "print '------------------------------------------'\n",
    "\n",
    "for twkey, twvalue in predicted_label_TW.items():\n",
    "    for twkey2, twvalue2 in predicted_label_TW.items():\n",
    "        if twkey != twkey2:\n",
    "            print error_similarity(twvalue,twvalue2), twkey, twkey2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def csr_vappend(a,b): #b est un vecteur ligne (np.array ou liste) et a est une sparse matrix\n",
    "    if(type(a)== list):\n",
    "        a=np.array([a]).T\n",
    "    if(type(b)== list):\n",
    "        b=np.array([b]).T\n",
    "    if(type(a)!= scipy.sparse.csr.csr_matrix):\n",
    "        a=scipy.sparse.csr_matrix(a)\n",
    "    if(type(b)!= scipy.sparse.csr.csr_matrix):\n",
    "        b=scipy.sparse.csr_matrix(b)\n",
    "        \n",
    "    return scipy.sparse.hstack([a,b], format ='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "created_features_train = load_sparse_csr(path+'train_new_feat.npz')\n",
    "created_features_test  = load_sparse_csr(path+'test_new_feat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### LOG REG ######\n",
    "add_label = 1\n",
    "add_proba = 1\n",
    "# Add PROBA Logistic Regression TW\n",
    "if(add_proba):\n",
    "    new_feat_train = lrtf.predict_proba(data_train)[:,0].tolist()\n",
    "    new_feat_test = lrtf.predict_proba(data_test)[:,0].tolist()\n",
    "\n",
    "# Add PROBA Logistic Regression TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, lrtw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, lrtw.predict_proba(data_test_tw)[:,0].tolist())\n",
    "\n",
    "###### SGD ########\n",
    "\n",
    "# Add SGD TF\n",
    "#new_feat_train = csr_vappend(new_feat_train, sgd_tf.predict(data_train).tolist())\n",
    "#new_feat_test = csr_vappend(new_feat_test, sgd_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add SGD TW\n",
    "new_feat_train = csr_vappend(new_feat_train, sgd_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, sgd_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### LINEAR SVC #######\n",
    "\n",
    "# Add Linear SVC TF\n",
    "#new_feat_train = csr_vappend(new_feat_train, svc_tf.predict(data_train).tolist())\n",
    "#new_feat_test = csr_vappend(new_feat_test, svc_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add Linear SVC TW\n",
    "new_feat_train = csr_vappend(new_feat_train, svc_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, svc_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### MULTINOMIAL NAIVE BAYES ######\n",
    "\n",
    "# Add Multinomial TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict(data_train).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA Multinomial TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict_proba(data_train)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### EXTRA TREES #######\n",
    "\n",
    "# Add TREES TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict(data_train).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA TREES TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict_proba(data_train)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "\n",
    "\n",
    "# Add TREES TW\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict(data_train_tw).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA TREES TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict_proba(data_test_tw)[:,0].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### ADABOOST #######\n",
    "\n",
    "# Add adaboost TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict(data_train).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA adaboost TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict_proba(data_train)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "\n",
    "# Add adaboost TW\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict(data_train_tw).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA adaboost TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict_proba(data_test_tw)[:,0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add created features\n",
    "new_feat_train = csr_vappend(new_feat_train, created_features_train)\n",
    "new_feat_test = csr_vappend(new_feat_test, created_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_ = csr_vappend(new_feat_train, data_train)\n",
    "data_test_ = csr_vappend(new_feat_test, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Layer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Random Forest - Score on test_data : ', 0.95023999999999997)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomF_final = RandomForestClassifier(n_estimators=2000, min_samples_split=2, min_samples_leaf=1, n_jobs = -1)\n",
    "randomF_final.fit(data_train_, label_train)\n",
    "predicted_label = randomF_final.predict(data_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVM - Best C & associated score', {'C': 0.001}, 1.0)\n",
      "('SVM - Score on test_data : ', 0.95135999999999998)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(0.001, 0.6, 15)}\n",
    "\n",
    "logreg_final = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "logreg_final.fit(new_feat_train, label_train)\n",
    "predicted_label = logreg_final.predict(new_feat_test)\n",
    "\n",
    "\n",
    "print(\"SVM - Best C & associated score\", logreg_final.best_params_, logreg_final.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD - Score on test data : ', 0.90383999999999998)\n"
     ]
    }
   ],
   "source": [
    "alg = SGDClassifier(loss='modified_huber', n_iter=100, random_state=0, shuffle=True, penalty='l2')\n",
    "alg.fit( new_feat_train, label_train )\n",
    "predicted_label = alg.predict(new_feat_test)\n",
    "\n",
    "print(\"SGD - Score on test data : \", score(label_test, predicted_label_SGD_TF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ExtraTrees - Score on test_data : ', 0.94223999999999997)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "alg = ExtraTreesClassifier(n_estimators=200, max_depth=None, min_samples_split=1, n_jobs = 1)\n",
    "alg.fit(data_train_, label_train)\n",
    "predicted_label = alg.predict(data_test_)\n",
    "\n",
    "print(\"ExtraTrees - Score on test_data : \", score(label_test, predicted_label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
