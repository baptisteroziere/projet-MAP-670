{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import scipy\n",
    "import csv\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.csr_matrix(( loader['data'], loader['indices'], loader['indptr']),\n",
    "                     shape = loader['shape'])\n",
    "        \n",
    "def load_csv(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = '\\n')\n",
    "        array = [float(row[0]) for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_feature_names(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter= '\\n')\n",
    "        array = [row for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_sparse_coo(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.coo_matrix((loader['data'],(loader['row'],loader['col'])),\n",
    "                     shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "def score(true_label, predicted_label):\n",
    "    return 1 - zero_one_loss(true_label,predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "#### Loading the data ####\n",
    "path = \"bapt_tfidf/\"\n",
    "data_train_train_tf = load_sparse_csr(path+'data_train.npz')\n",
    "data_train_test_tf = load_sparse_csr(path+'data_test.npz')\n",
    "data_train = scipy.sparse.vstack([data_train_train_tf, data_train_test_tf], format ='csr')\n",
    "data_test = load_sparse_csr(path+'data_test_test.npz')\n",
    "\n",
    "#### Loading the labels ####\n",
    "label_train = load_csv(path+'label_train.csv')\n",
    "label_test = load_csv(path+'label_test.csv')\n",
    "label_train = label_train + label_test\n",
    "\n",
    "#### Loading the created features ####\n",
    "created_feat_train_train = load_sparse_csr(path+'train_new_feat.npz')\n",
    "created_feat_train_test = load_sparse_csr(path+'test_new_feat.npz')\n",
    "created_features_train = scipy.sparse.vstack([created_feat_train_train, created_feat_train_test], format = 'csr')\n",
    "created_features_test = load_sparse_csr(path+'test_test_new_feat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Adding the good and bad grades #### \n",
    "data_train = scipy.sparse.hstack([data_train, created_features_train[:,-2:]])\n",
    "data_test = scipy.sparse.hstack([data_test, created_features_test[:,-2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80000) (25000, 80000)\n"
     ]
    }
   ],
   "source": [
    "nb_feat = 80000\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "fselect = SelectKBest(chi2 , k=nb_feat)\n",
    "data_train = fselect.fit_transform(data_train, label_train)\n",
    "data_test = fselect.transform(data_test)\n",
    "print data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_train_all = [load_sparse_csr('tw_sw{}_all_train_train.npz'.format(k)) for k in range(1,5)]\n",
    "data_train_test_all = [load_sparse_csr('tw_sw{}_all_train_test.npz'.format(k)) for k in range(1,5)]\n",
    "data_train_all = [scipy.sparse.vstack([data_train_train_all[i], data_train_test_all[i]], format ='csr') for i in range(0,4)]\n",
    "data_test_all = [load_sparse_csr('tw_sw{}_all_test.npz'.format(k)) for k in range(1,5)]\n",
    "\n",
    "label_train_tw =label_train\n",
    "#label_train_tw = load_csv('label_train.csv')\n",
    "#label_test_tw = load_csv('labels_train_test.csv')\n",
    "#label_train_tw = label_train_tw +label_test_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 99627)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_all[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "normalizer_all = map(lambda x: MaxAbsScaler().fit(x), data_train_all)\n",
    "\n",
    "scaler =MaxAbsScaler()\n",
    "scaler.partial_fit(data_test)\n",
    "scaler.partial_fit(data_train)\n",
    "scaler.transform(data_test)\n",
    "scaler.transform(data_train)\n",
    "\n",
    "data_train_all_norm = [normalizer_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_norm = [normalizer_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SelectKBest(f_classif , k=data_train_all[0].shape[1]/100).fit(data_train_all[0],label_train_tw)\n",
    "fselect_all = [SelectKBest(f_classif , k=data_train_all[i].shape[1]/100).fit(\n",
    "        data_train_all[i],label_train_tw) for i in range(len(data_train_all))]\n",
    "data_train_all_selec = [fselect_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_selec = [fselect_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n",
    "\n",
    "fselect_all_norm = [SelectKBest(f_classif , k=data_train_all_norm[i].shape[1]/100).fit(\n",
    "        data_train_all_norm[i],label_train_tw) for i in range(len(data_train_all_norm))]\n",
    "\n",
    "data_train_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_train_all_norm[i]) for i in range(len(data_train_all_norm))]\n",
    "data_test_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_test_all_norm[i]) for i in range(len(data_test_all_norm))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_tw = data_train_all_norm [3]\n",
    "data_test_tw = data_test_all_norm [3]\n",
    "\n",
    "data_train_tw = data_train_tw[:,0:-25]\n",
    "data_test_tw = data_test_tw[:,0:-25]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 99602) (25000, 99602)\n"
     ]
    }
   ],
   "source": [
    "print data_train_tw.shape, data_test_tw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train_layer2 = 5000\n",
    "data_train2 = data_train[-nb_train_layer2:]\n",
    "data_train = data_train[0:-nb_train_layer2]\n",
    "\n",
    "data_train2_tw = data_train_tw[-nb_train_layer2:]\n",
    "data_train_tw = data_train_tw[0:-nb_train_layer2]\n",
    "\n",
    "label_train2 = label_train[-nb_train_layer2:]\n",
    "label_train = label_train[0:-nb_train_layer2]\n",
    "\n",
    "created_features_train2 = created_features_train[-nb_train_layer2:]\n",
    "created_features_train = created_features_train[0:-nb_train_layer2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 80000) (20000, 80000) (5000, 99602) (20000, 99602)\n"
     ]
    }
   ],
   "source": [
    "print data_train2.shape, data_train.shape, data_train2_tw.shape, data_train_tw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "- Adding the proba (instead of the label) is better for the final predition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LogReg - Best C & associated score', {'C': 33598.182862837813}, 0.92159999999999997)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.logspace(2, 5, 20)}\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrtf = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "lrtf = lrtf.fit(data_train, label_train)\n",
    "predicted_label_lrtf = lrtf.predict(data_test)\n",
    "\n",
    "\n",
    "print(\"LogReg - Best C & associated score\", lrtf.best_params_, lrtf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LogReg - Best C & associated score', {'C': 1.0}, 0.87809999999999999)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.logspace(0, 2, 20)}\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrtw = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "lrtw = lrtw.fit(data_train_tw, label_train)\n",
    "predicted_label_lrtw = lrtw.predict(data_test_tw)\n",
    "\n",
    "print(\"LogReg - Best C & associated score\", lrtw.best_params_, lrtw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier\n",
    "- Impossible to predict a proba, just labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import SGDClassifier\n",
    "#alphas = np.logspace(-6, -2, 10)\n",
    "#sgd_tf = GridSearchCV(SGDClassifier(loss='modified_huber', n_iter=200, random_state=0, shuffle=True, penalty='l2')\n",
    "#                     ,dict(alpha=alphas)\n",
    "#                     ,n_jobs = -1\n",
    "#                     ,cv=10)\n",
    "#sgd_tf.fit( data_train, label_train )\n",
    "#predicted_label_SGD_TF = sgd_tf.predict(data_test)\n",
    "#print(\"SGD squared hinge: Best alpha and associated score: \", sgd_tf.best_params_, sgd_tf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SGD squared hinge: Best alpha and associated score: ', {'alpha': 0.0016681005372000592}, 0.87885000000000002)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "alphas = np.logspace(-5, 0, 10)\n",
    "alphas = [ 0.0016681005372000592]\n",
    "sgd_tw = GridSearchCV(SGDClassifier(loss='modified_huber', n_iter=300, random_state=0, shuffle=True, penalty='l2'),\n",
    "                      dict(alpha=alphas)\n",
    "                     ,n_jobs = -1\n",
    "                     ,cv=5)\n",
    "sgd_tw.fit( data_train_tw, label_train )\n",
    "predicted_label_SGD_TW = sgd_tw.predict(data_test_tw)\n",
    "print(\"SGD squared hinge: Best alpha and associated score: \", sgd_tw.best_params_, sgd_tw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC\n",
    "- Do not predict proba, only labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "#Cs = {'C': np.logspace(-2, 1, 15)}\n",
    "#svc_tf = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "#svc_tf.fit(data_train, label_train)\n",
    "#predicted_label_SVC_TF = svc_tf.predict(data_test)\n",
    "\n",
    "#print(\"Linear SVC - Best C & associated score\", svc_tf.best_params_, svc_tf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Linear SVC - Best C & associated score', {'C': 0.054555947811685171}, 0.87865000000000004)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "Cs = {'C': np.logspace(-3,0, 20)}\n",
    "\n",
    "svc_tw = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "svc_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_SVC_TW = svc_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"Linear SVC - Best C & associated score\", svc_tw.best_params_, svc_tw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n",
    "- Able to return the label, the proba, and the log_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Multinomial - Best alpha & associated score', {'alpha': 0.0021209508879201904}, 0.94389999999999996)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "alphas = {'alpha': np.logspace(-4, 1, 50)}\n",
    "multinom_tf = GridSearchCV(MultinomialNB(), alphas, n_jobs = -1)\n",
    "multinom_tf.fit(data_train, label_train)\n",
    "predicted_label_MN_TF = multinom_tf.predict(data_test)\n",
    "\n",
    "print(\"Multinomial - Best alpha & associated score\", multinom_tf.best_params_, multinom_tf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bernouilli - Best alpha & associated score', {'alpha': 28.117686979742309}, 0.8548)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "alphas = {'alpha': np.logspace(-1, 4, 50)}\n",
    "nbtw = GridSearchCV(BernoulliNB(), alphas, n_jobs = -1)\n",
    "nbtw.fit(data_train_tw, label_train)\n",
    "predicted_label_NB_TW = nbtw.predict(data_test_tw)\n",
    "\n",
    "print(\"Bernouilli - Best alpha & associated score\", nbtw.best_params_, nbtw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTrees\n",
    "- Can predict label, proba AND log proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extratrees_tf = ExtraTreesClassifier(n_estimators=50, max_depth=None, min_samples_split=1, random_state=0, n_jobs = -1)\n",
    "extratrees_tf.fit(data_train, label_train)\n",
    "predicted_label_extratrees_tf = extratrees_tf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extratrees_tw = ExtraTreesClassifier(n_estimators=50, max_depth=None, min_samples_split=1, random_state=0, n_jobs = -1)\n",
    "extratrees_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_extratrees_tw = extratrees_tw.predict(data_test_tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "- Can predict label, proba AND log proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_tf = AdaBoostClassifier(n_estimators=50)\n",
    "adaboost_tf.fit(data_train, label_train)\n",
    "predicted_label_adaboost_tf = adaboost_tf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adaboost_tw = AdaBoostClassifier(n_estimators=50)\n",
    "adaboost_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_adaboost_tw = adaboost_tw.predict(data_test_tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def csr_vappend(a,b): #b est un vecteur ligne (np.array ou liste) et a est une sparse matrix\n",
    "    if(type(a)== list):\n",
    "        a=np.array([a]).T\n",
    "    if(type(b)== list):\n",
    "        b=np.array([b]).T\n",
    "    if(type(a)!= scipy.sparse.csr.csr_matrix):\n",
    "        a=scipy.sparse.csr_matrix(a)\n",
    "    if(type(b)!= scipy.sparse.csr.csr_matrix):\n",
    "        b=scipy.sparse.csr_matrix(b)\n",
    "        \n",
    "    return scipy.sparse.hstack([a,b], format ='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### LOG REG ######\n",
    "add_label = 1\n",
    "add_proba = 1\n",
    "# Add PROBA Logistic Regression TW\n",
    "if(add_proba):\n",
    "    new_feat_train = lrtf.predict_proba(data_train2)[:,0].tolist()\n",
    "    new_feat_test = lrtf.predict_proba(data_test)[:,0].tolist()\n",
    "\n",
    "# Add PROBA Logistic Regression TW\n",
    "#if(add_proba):\n",
    "#    new_feat_train = csr_vappend(new_feat_train, lrtw.predict_proba(data_train2_tw)[:,0].tolist())\n",
    "#    new_feat_test = csr_vappend(new_feat_test, lrtw.predict_proba(data_test_tw)[:,0].tolist())\n",
    "\n",
    "###### SGD ########\n",
    "\n",
    "# Add SGD TF\n",
    "#new_feat_train = csr_vappend(new_feat_train, sgd_tf.predict(data_train2).tolist())\n",
    "#new_feat_test = csr_vappend(new_feat_test, sgd_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add SGD TW\n",
    "new_feat_train = csr_vappend(new_feat_train, sgd_tw.predict(data_train2_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, sgd_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### LINEAR SVC #######\n",
    "\n",
    "# Add Linear SVC TF\n",
    "#new_feat_train = csr_vappend(new_feat_train, svc_tf.predict(data_train2).tolist())\n",
    "#new_feat_test = csr_vappend(new_feat_test, svc_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add Linear SVC TW\n",
    "new_feat_train = csr_vappend(new_feat_train, svc_tw.predict(data_train2_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, svc_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### MULTINOMIAL NAIVE BAYES ######\n",
    "\n",
    "# Add Multinomial TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict(data_train2).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA Multinomial TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict_proba(data_train2)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "# Add Bernouilli TW\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, nbtw.predict(data_train2_tw).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, nbtw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA Bernouilli TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, nbtw.predict_proba(data_train2_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, nbtw.predict_proba(data_test_tw)[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### EXTRA TREES #######\n",
    "\n",
    "# Add TREES TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict(data_train2).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA TREES TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict_proba(data_train2)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "\n",
    "\n",
    "# Add TREES TW\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict(data_train2_tw).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA TREES TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict_proba(data_train2_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict_proba(data_test_tw)[:,0].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### ADABOOST #######\n",
    "\n",
    "# Add adaboost TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict(data_train2).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA adaboost TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict_proba(data_train2)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "\n",
    "# Add adaboost TW\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict(data_train2_tw).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA adaboost TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict_proba(data_train2_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict_proba(data_test_tw)[:,0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 15)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "created_features_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add created features\n",
    "new_feat_train = csr_vappend(new_feat_train, created_features_train2)\n",
    "new_feat_test = csr_vappend(new_feat_test, created_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_ = csr_vappend(new_feat_train, data_train2)\n",
    "data_test_ = csr_vappend(new_feat_test, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Layer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "randomF_final = RandomForestClassifier(n_estimators=1000, min_samples_split=2, min_samples_leaf=1, n_jobs = -1)\n",
    "randomF_final.fit(data_train_, label_train2)\n",
    "predicted_label_rf = randomF_final.predict(data_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVM - Best C & associated score', {'C': 52.983169062837071}, 0.97140000000000004)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.logspace(-2, 2, 30)}\n",
    "\n",
    "logreg_final = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "logreg_final.fit(new_feat_train, label_train2)\n",
    "predicted_label_logreg = logreg_final.predict(new_feat_test)\n",
    "\n",
    "\n",
    "print(\"SVM - Best C & associated score\", logreg_final.best_params_, logreg_final.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91959999999999997"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(predicted_label_rf, predicted_label_logreg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(predicted_label_rf)/len(predicted_label_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_submission(labels, filepath):\n",
    "    with open(filepath, 'w') as file:\n",
    "        for i in range(25000):\n",
    "            file.write(\"{}\\n\".format(format(i, '05d')+ \"\\t\" + str(labels[i])))\n",
    "\n",
    "save_submission(predicted_label_logreg, \"submission_logreg_no_overfit.txt\")\n",
    "save_submission(predicted_label_rf, \"submission_rf_no_overfit.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "171\n",
      "252\n",
      "331\n",
      "334\n",
      "361\n",
      "383\n",
      "417\n",
      "422\n",
      "452\n",
      "535\n",
      "542\n",
      "558\n",
      "674\n",
      "677\n",
      "718\n",
      "762\n",
      "867\n",
      "939\n",
      "1008\n",
      "1074\n",
      "1094\n",
      "1135\n",
      "1263\n",
      "1298\n",
      "1316\n",
      "1366\n",
      "1394\n",
      "1499\n",
      "1542\n",
      "1661\n",
      "1680\n",
      "1833\n",
      "1869\n",
      "1926\n",
      "1931\n",
      "1990\n",
      "2035\n",
      "2050\n",
      "2065\n",
      "2078\n",
      "2091\n",
      "2095\n",
      "2128\n",
      "2136\n",
      "2161\n",
      "2191\n",
      "2212\n",
      "2339\n",
      "2426\n",
      "2446\n",
      "2552\n",
      "2554\n",
      "2560\n",
      "2614\n",
      "2659\n",
      "2666\n",
      "2718\n",
      "2746\n",
      "2762\n",
      "2775\n",
      "2787\n",
      "2809\n",
      "2830\n",
      "2846\n",
      "2877\n",
      "2923\n",
      "2927\n",
      "2928\n",
      "2976\n",
      "3028\n",
      "3035\n",
      "3086\n",
      "3106\n",
      "3110\n",
      "3125\n",
      "3283\n",
      "3298\n",
      "3300\n",
      "3354\n",
      "3398\n",
      "3432\n",
      "3453\n",
      "3465\n",
      "3512\n",
      "3617\n",
      "3643\n",
      "3696\n",
      "3713\n",
      "3734\n",
      "3749\n",
      "3774\n",
      "3793\n",
      "3847\n",
      "3876\n",
      "3880\n",
      "3885\n",
      "3912\n",
      "3967\n",
      "3969\n"
     ]
    }
   ],
   "source": [
    "count = 0 \n",
    "for i, label in enumerate(predicted_label_logreg):\n",
    "    if(label==0 and predicted_label_rf[i]==1 and count<100):\n",
    "        print i\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86307999999999996"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(predicted_label_lrtf, predicted_label_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85692000000000002"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(predicted_label_rf, predicted_label_lrtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63388"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(predicted_label_logreg, predicted_label_NB_TW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(predicted_label_logreg)/len(predicted_label_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alg = SGDClassifier(loss='modified_huber', n_iter=500, random_state=0, shuffle=True, penalty='l2')\n",
    "alg.fit( new_feat_train, label_train )\n",
    "predicted_label_sgd = alg.predict(new_feat_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "\n",
    "alg = ExtraTreesClassifier(n_estimators=200, max_depth=None, min_samples_split=1, n_jobs = 1)\n",
    "alg.fit(data_train_, label_train)\n",
    "predicted_label = alg.predict(data_test_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
