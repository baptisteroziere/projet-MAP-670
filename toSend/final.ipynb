{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import numpy as np\n",
    "import scipy\n",
    "import csv\n",
    "\n",
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.csr_matrix(( loader['data'], loader['indices'], loader['indptr']),\n",
    "                     shape = loader['shape'])\n",
    "        \n",
    "def load_csv(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter = '\\n')\n",
    "        array = [float(row[0]) for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_feature_names(filename):\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter= '\\n')\n",
    "        array = [row for row in reader]\n",
    "        return array\n",
    "    \n",
    "def load_sparse_coo(filename):\n",
    "    loader = np.load(filename)\n",
    "    return scipy.sparse.coo_matrix((loader['data'],(loader['row'],loader['col'])),\n",
    "                     shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "def score(true_label, predicted_label):\n",
    "    return 1 - zero_one_loss(true_label,predicted_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "#### Loading the data ####\n",
    "path = \"bapt_tfidf/\"\n",
    "data_train_train_tf = load_sparse_csr(path+'data_train.npz')\n",
    "data_train_test_tf = load_sparse_csr(path+'data_test.npz')\n",
    "data_train = scipy.sparse.vstack([data_train_train_tf, data_train_test_tf], format ='csr')\n",
    "data_test = load_sparse_csr(path+'data_test_test.npz')\n",
    "\n",
    "#### Loading the labels ####\n",
    "label_train = load_csv(path+'label_train.csv')\n",
    "label_test = load_csv(path+'label_test.csv')\n",
    "label_train = label_train + label_test\n",
    "\n",
    "#### Loading the created features ####\n",
    "created_feat_train_train = load_sparse_csr(path+'train_new_feat.npz')\n",
    "created_feat_train_test = load_sparse_csr(path+'test_new_feat.npz')\n",
    "created_features_train = scipy.sparse.vstack([created_feat_train_train, created_feat_train_test], format = 'csr')\n",
    "created_features_test = load_sparse_csr(path+'test_test_new_feat.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Adding the good and bad grades #### \n",
    "data_train = scipy.sparse.hstack([data_train, created_features_train[:,-2:]])\n",
    "data_test = scipy.sparse.hstack([data_test, created_features_test[:,-2:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 80000) (25000, 80000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:165: RuntimeWarning: invalid value encountered in divide\n",
      "  chisq /= f_exp\n"
     ]
    }
   ],
   "source": [
    "nb_feat = 80000\n",
    "from sklearn.feature_selection.univariate_selection import SelectKBest, chi2, f_classif\n",
    "fselect = SelectKBest(chi2 , k=nb_feat)\n",
    "data_train = fselect.fit_transform(data_train, label_train)\n",
    "data_test = fselect.transform(data_test)\n",
    "print data_train.shape, data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TWIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_train_all = [load_sparse_csr('tw_sw{}_all_train_train.npz'.format(k)) for k in range(1,5)]\n",
    "data_train_test_all = [load_sparse_csr('tw_sw{}_all_train_test.npz'.format(k)) for k in range(1,5)]\n",
    "data_train_all = [scipy.sparse.vstack([data_train_train_all[i], data_train_test_all[i]], format ='csr') for i in range(0,4)]\n",
    "data_test_all = [load_sparse_csr('tw_sw{}_all_test.npz'.format(k)) for k in range(1,5)]\n",
    "\n",
    "label_train_tw =label_train\n",
    "#label_train_tw = load_csv('label_train.csv')\n",
    "#label_test_tw = load_csv('labels_train_test.csv')\n",
    "#label_train_tw = label_train_tw +label_test_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 99627)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_all[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "normalizer_all = map(lambda x: MaxAbsScaler().fit(x), data_train_all)\n",
    "\n",
    "scaler =MaxAbsScaler()\n",
    "scaler.partial_fit(data_test)\n",
    "scaler.partial_fit(data_train)\n",
    "scaler.transform(data_test)\n",
    "scaler.transform(data_train)\n",
    "\n",
    "data_train_all_norm = [normalizer_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_norm = [normalizer_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:113: UserWarning: Features [0 0 0 ..., 0 0 0] are constant.\n",
      "  UserWarning)\n",
      "/home/bat/anaconda2/lib/python2.7/site-packages/sklearn/feature_selection/univariate_selection.py:114: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "SelectKBest(f_classif , k=data_train_all[0].shape[1]/100).fit(data_train_all[0],label_train_tw)\n",
    "fselect_all = [SelectKBest(f_classif , k=data_train_all[i].shape[1]/100).fit(\n",
    "        data_train_all[i],label_train_tw) for i in range(len(data_train_all))]\n",
    "data_train_all_selec = [fselect_all[i].transform(data_train_all[i]) for i in range(len(data_train_all))]\n",
    "data_test_all_selec = [fselect_all[i].transform(data_test_all[i]) for i in range(len(data_test_all))]\n",
    "\n",
    "fselect_all_norm = [SelectKBest(f_classif , k=data_train_all_norm[i].shape[1]/100).fit(\n",
    "        data_train_all_norm[i],label_train_tw) for i in range(len(data_train_all_norm))]\n",
    "\n",
    "data_train_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_train_all_norm[i]) for i in range(len(data_train_all_norm))]\n",
    "data_test_all_norm_selec = [fselect_all_norm[i].transform(\n",
    "        data_test_all_norm[i]) for i in range(len(data_test_all_norm))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train_tw = data_train_all_norm [3]\n",
    "data_test_tw = data_test_all_norm [3]\n",
    "\n",
    "data_train_tw = data_train_tw[:,0:-25]\n",
    "data_test_tw = data_test_tw[:,0:-25]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 99602) (25000, 99602)\n"
     ]
    }
   ],
   "source": [
    "print data_train_tw.shape, data_test_tw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "- Adding the proba (instead of the label) is better for the final predition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cs = {'C': np.logspace(2, 5, 20)}\n",
    "Cs = {'C': np.linspace(1000, 1500, 10)}\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrtf = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "lrtf = lrtf.fit(data_train, label_train)\n",
    "predicted_label_lrtf = lrtf.predict(data_test)\n",
    "\n",
    "\n",
    "print(\"LogReg - Best C & associated score\", lrtf.best_params_, lrtf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Cs = {'C': np.logspace(0, 2, 20)}\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrtw = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "lrtw = lrtw.fit(data_train_tw, label_train_tw)\n",
    "predicted_label_lrtw = lrtw.predict(data_test_tw)\n",
    "\n",
    "print(\"LogReg - Best C & associated score\", lrtw.best_params_, lrtw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD Classifier\n",
    "- Impossible to predict a proba, just labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.linear_model import SGDClassifier\n",
    "#alphas = np.logspace(-6, -2, 10)\n",
    "#sgd_tf = GridSearchCV(SGDClassifier(loss='modified_huber', n_iter=200, random_state=0, shuffle=True, penalty='l2')\n",
    "#                     ,dict(alpha=alphas)\n",
    "#                     ,n_jobs = -1\n",
    "#                     ,cv=10)\n",
    "#sgd_tf.fit( data_train, label_train )\n",
    "#predicted_label_SGD_TF = sgd_tf.predict(data_test)\n",
    "#print(\"SGD squared hinge: Best alpha and associated score: \", sgd_tf.best_params_, sgd_tf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "alphas = np.logspace(-5, 0, 15)\n",
    "sgd_tw = GridSearchCV(SGDClassifier(loss='modified_huber', n_iter=500, random_state=0, shuffle=True, penalty='l2'),\n",
    "                      dict(alpha=alphas)\n",
    "                     ,n_jobs = -1\n",
    "                     ,cv=10)\n",
    "sgd_tw.fit( data_train_tw, label_train )\n",
    "predicted_label_SGD_TW = sgd_tw.predict(data_test_tw)\n",
    "print(\"SGD squared hinge: Best alpha and associated score: \", sgd_tw.best_params_, sgd_tw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearSVC\n",
    "- Do not predict proba, only labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.svm import LinearSVC\n",
    "\n",
    "#Cs = {'C': np.logspace(-2, 1, 15)}\n",
    "#svc_tf = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "#svc_tf.fit(data_train, label_train)\n",
    "#predicted_label_SVC_TF = svc_tf.predict(data_test)\n",
    "\n",
    "#print(\"Linear SVC - Best C & associated score\", svc_tf.best_params_, svc_tf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "Cs = {'C': np.logspace(-3,0, 30)}\n",
    "svc_tw = GridSearchCV(LinearSVC(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "svc_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_SVC_TW = svc_tw.predict(data_test_tw)\n",
    "\n",
    "print(\"Linear SVC - Best C & associated score\", svc_tw.best_params_, svc_tw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes\n",
    "- Able to return the label, the proba, and the log_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "alphas = {'alpha': np.logspace(-4, 1, 80)}\n",
    "multinom_tf = GridSearchCV(MultinomialNB(), alphas, n_jobs = -1)\n",
    "multinom_tf.fit(data_train, label_train)\n",
    "predicted_label_MN_TF = multinom_tf.predict(data_test)\n",
    "\n",
    "print(\"Multinomial - Best alpha & associated score\", multinom_tf.best_params_, multinom_tf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "alphas = {'alpha': np.logspace(-2, 4, 80)}\n",
    "nbtw = GridSearchCV(BernoulliNB(), alphas, n_jobs = -1)\n",
    "nbtw.fit(data_train_tw, label_train_tw)\n",
    "predicted_label_NB_TW = nbtw.predict(data_test_tw)\n",
    "\n",
    "print(\"Bernouilli - Best alpha & associated score\", nbtw.best_params_, nbtw.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExtraTrees\n",
    "- Can predict label, proba AND log proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "extratrees_tf = ExtraTreesClassifier(n_estimators=300, max_depth=None, min_samples_split=1, random_state=0, n_jobs = -1)\n",
    "extratrees_tf.fit(data_train, label_train)\n",
    "predicted_label_extratrees_tf = extratrees_tf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extratrees_tw = ExtraTreesClassifier(n_estimators=300, max_depth=None, min_samples_split=1, random_state=0, n_jobs = -1)\n",
    "extratrees_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_extratrees_tw = extratrees_tw.predict(data_test_tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "- Can predict label, proba AND log proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "adaboost_tf = AdaBoostClassifier(n_estimators=300)\n",
    "adaboost_tf.fit(data_train, label_train)\n",
    "predicted_label_adaboost_tf = adaboost_tf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adaboost_tw = AdaBoostClassifier(n_estimators=300)\n",
    "adaboost_tw.fit(data_train_tw, label_train)\n",
    "predicted_label_adaboost_tw = adaboost_tw.predict(data_test_tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembling the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def csr_vappend(a,b): #b est un vecteur ligne (np.array ou liste) et a est une sparse matrix\n",
    "    if(type(a)== list):\n",
    "        a=np.array([a]).T\n",
    "    if(type(b)== list):\n",
    "        b=np.array([b]).T\n",
    "    if(type(a)!= scipy.sparse.csr.csr_matrix):\n",
    "        a=scipy.sparse.csr_matrix(a)\n",
    "    if(type(b)!= scipy.sparse.csr.csr_matrix):\n",
    "        b=scipy.sparse.csr_matrix(b)\n",
    "        \n",
    "    return scipy.sparse.hstack([a,b], format ='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### LOG REG ######\n",
    "add_label = 1\n",
    "add_proba = 1\n",
    "# Add PROBA Logistic Regression TW\n",
    "if(add_proba):\n",
    "    new_feat_train = lrtf.predict_proba(data_train)[:,0].tolist()\n",
    "    new_feat_test = lrtf.predict_proba(data_test)[:,0].tolist()\n",
    "\n",
    "# Add PROBA Logistic Regression TW\n",
    "#if(add_proba):\n",
    "#    new_feat_train = csr_vappend(new_feat_train, lrtw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "#    new_feat_test = csr_vappend(new_feat_test, lrtw.predict_proba(data_test_tw)[:,0].tolist())\n",
    "\n",
    "###### SGD ########\n",
    "\n",
    "# Add SGD TF\n",
    "#new_feat_train = csr_vappend(new_feat_train, sgd_tf.predict(data_train).tolist())\n",
    "#new_feat_test = csr_vappend(new_feat_test, sgd_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add SGD TW\n",
    "new_feat_train = csr_vappend(new_feat_train, sgd_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, sgd_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### LINEAR SVC #######\n",
    "\n",
    "# Add Linear SVC TF\n",
    "#new_feat_train = csr_vappend(new_feat_train, svc_tf.predict(data_train).tolist())\n",
    "#new_feat_test = csr_vappend(new_feat_test, svc_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add Linear SVC TW\n",
    "new_feat_train = csr_vappend(new_feat_train, svc_tw.predict(data_train_tw).tolist())\n",
    "new_feat_test = csr_vappend(new_feat_test, svc_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "###### MULTINOMIAL NAIVE BAYES ######\n",
    "\n",
    "# Add Multinomial TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict(data_train).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA Multinomial TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, multinom_tf.predict_proba(data_train)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, multinom_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "# Add Bernouilli TW\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, nbtw.predict(data_train_tw).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, nbtw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA Bernouilli TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, nbtw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, nbtw.predict_proba(data_test_tw)[:,0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##### EXTRA TREES #######\n",
    "\n",
    "# Add TREES TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict(data_train).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA TREES TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tf.predict_proba(data_train)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "\n",
    "\n",
    "# Add TREES TW\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict(data_train_tw).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA TREES TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, extratrees_tw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, extratrees_tw.predict_proba(data_test_tw)[:,0].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### ADABOOST #######\n",
    "\n",
    "# Add adaboost TF\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict(data_train).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict(data_test).tolist())\n",
    "\n",
    "# Add PROBA adaboost TF\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tf.predict_proba(data_train)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tf.predict_proba(data_test)[:,0].tolist())\n",
    "\n",
    "\n",
    "# Add adaboost TW\n",
    "if(add_label):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict(data_train_tw).tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict(data_test_tw).tolist())\n",
    "\n",
    "# Add PROBA adaboost TW\n",
    "if(add_proba):\n",
    "    new_feat_train = csr_vappend(new_feat_train, adaboost_tw.predict_proba(data_train_tw)[:,0].tolist())\n",
    "    new_feat_test = csr_vappend(new_feat_test, adaboost_tw.predict_proba(data_test_tw)[:,0].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add created features\n",
    "new_feat_train = csr_vappend(new_feat_train, created_features_train)\n",
    "new_feat_test = csr_vappend(new_feat_test, created_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train_ = csr_vappend(new_feat_train, data_train)\n",
    "data_test_ = csr_vappend(new_feat_test, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Layer Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SVM - Best C & associated score', {'C': 0.043785714285714282}, 1.0)\n"
     ]
    }
   ],
   "source": [
    "Cs = {'C': np.linspace(0.001, 0.6, 15)}\n",
    "\n",
    "logreg_final = GridSearchCV(LogisticRegression(penalty = 'l2'), Cs, n_jobs = -1)\n",
    "logreg_final.fit(new_feat_train, label_train)\n",
    "predicted_label_logreg = logreg_final.predict(new_feat_test)\n",
    "\n",
    "\n",
    "print(\"SVM - Best C & associated score\", logreg_final.best_params_, logreg_final.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def save_submission(labels, filepath):\n",
    "    with open(filepath, 'w') as file:\n",
    "        for i in range(25000):\n",
    "            file.write(\"{}\\n\".format(format(i, '05d')+ \"\\t\" + str(labels[i])))\n",
    "\n",
    "save_submission(predicted_label_logreg, \"submission_logreg.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
